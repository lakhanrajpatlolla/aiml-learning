{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakhanrajpatlolla/aiml-learning/blob/master/TalentSprint_IIIT_Colab_CNN_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7W6IuZjFVoD"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67YV6IpOhBhu"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook aims at discovering Convolutional Neural Network. We will see the theory behind it, and an implementation in Pytorch on FashionMNIST dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWJmsKzdhBhv",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# ! pip install --user -r requirements.txt\n",
        "#! pip install --user torchviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XJ35JrOfciN",
        "outputId": "aed29fe5-48f4-46d3-ae58-67e9d76443f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchviz) (2.5.1+cu124)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torchviz)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torchviz)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torchviz)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torchviz)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torchviz)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torchviz)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n",
            "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchviz\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchviz-0.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torchviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp6PPxbkhBhz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "from torchviz import make_dot\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "os.environ[\"PATH\"] += os.pathsep + r\"libraries/graphviz-2.38/release/bin\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3qF-qJYhBhz"
      },
      "source": [
        "Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes\n",
        "\n",
        "![FashionMNIST Dataset](https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/doc/img/fashion-mnist-sprite.png)\n",
        "\n",
        "Pytorch's torchvision module conveniently packages the FashionMNIST dataset into a `torchvision.datasets.FashionMNIST` class for us. We simply need to specify the dataset split (train/test) and the transformations and augmentations we want to apply on each image. We wrap the dataset objects via Pytorch's `torch.utils.data.DataLoader` class to get dataloaders which will return entire batches of samples, and also optionally shuffle the dataset internally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB4iDtHXhBhz",
        "outputId": "7300a725-1ab9-4d4c-bcf9-ee71fd52a45f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 200kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.78MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 21.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Training time transformations and problem specific data augmentations can be applied here.\n",
        "see : https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "'''\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # We've computed the mean and variance for this dataset beforehand, so we can plug it in here\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "'''\n",
        "FashionMNIST is a subclass of torch.utils.data.Dataset, and have __getitem__ and __len__ methods implemented. For creating\n",
        "custom datasets you will have to inherit Dataset class and override __len__() and __getitem__()\n",
        "'''\n",
        "dataset_train = datasets.FashionMNIST(\n",
        "    root='./data', train=True, download=True, transform=transforms_train\n",
        ")\n",
        "'''\n",
        "Pass dataset object to DataLoader, which will later be used for iterating over minibatches\n",
        "'''\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train, batch_size=128, shuffle=True,\n",
        ")\n",
        "\n",
        "'''\n",
        "Repeat the same thing (defining transforms => dataset instantiation => dataloader creationg) for the test set\n",
        "'''\n",
        "transforms_test =transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # We've computed the mean and variance for this dataset beforehand, so we can plug it in here\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "dataset_test = datasets.FashionMNIST(\n",
        "    root='./data', train=False, download=False, transform=transforms_test\n",
        ")\n",
        "\n",
        "dataloader_test = DataLoader(\n",
        "    dataset_test, batch_size=128, shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QQ3el0-hBhz"
      },
      "source": [
        "We now create a CNN class, which has to be a subclass of `torch.nn.Module` and have its own `__init__` and `forward` functions.\n",
        "\n",
        "We choose a simple architecture with `3 convolutional blocks` followed by `2 fully connected blocks`.\n",
        "\n",
        "For layers that do not have any parameters, i.e. layers that are simple mathematical operations on the input, such as ReLU, sigmoid, tanh, softmax, dropout, etc., Pytorch provides a `torch.nn.functional` module with such layers.\n",
        "\n",
        "While one can create a ReLU layer by using `nn.ReLU`, it's easier to just call `torch.nn.functional.relu` on a tensor. This helps reduce clutter, since large models can have many such layers.\n",
        "\n",
        "NOTE: We import `torch.nn.functional` as the alias `F`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "PIq0tshchBhz",
        "outputId": "24861121-5bf0-4bc1-f07d-0f02d6150c9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128]) torch.Size([128, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cnn.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # nn.Conv2d API : torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1)  # 32 filters of 5x5 size and depth 1 (since input channel = 1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5) # 32 filters of 5x5 size and depth 32 (since input channel =  1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5) # 64 filters of 5x5 size and depth 32 #params = 64x5x5x32 + 64\n",
        "        # nn.Linear API : torch.nn.Linear(in_features, out_features, bias=True)\n",
        "        self.fc1 = nn.Linear(3*3*64, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # BLOCK 1: CONV + RELU\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # BLOCK 2: CONV + MAXPOOL + RELU + DROPOUT\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        # BLOCK 3: CONV + MAXPOOL + RELU + DROPOUT\n",
        "        x = F.relu(F.max_pool2d(self.conv3(x),2))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        # FLATTEN\n",
        "        x = x.flatten(start_dim=1)\n",
        "        # BLOCK 4: FC + RELU + DROPOUT\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        # BLOCK 5: FC + LOG SOFTMAX\n",
        "        x = F.log_softmax(self.fc2(x), dim=1)\n",
        "        return x\n",
        "\n",
        "model = CNN()\n",
        "print(model)\n",
        "\n",
        "# get a random training batch\n",
        "iterator = iter(dataloader_train)\n",
        "X_batch, y_batch = next(iterator)\n",
        "print(X_batch.shape, y_batch.shape, model(X_batch).shape)\n",
        "\n",
        "# pass a batch through the model and visualize the architecture\n",
        "# NOTE: we do not have to explicitly call model.forward(inputs), instead we just do model(inputs)\n",
        "# This is because PyTorch internally takes care of, giving us this syntactic sugar\n",
        "make_dot(model(X_batch), params=dict(model.named_parameters())).render(\"cnn\", format=\"png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thiKjDeKhBh0"
      },
      "source": [
        "Now we create some utility functions to help with the training and evaluation process. Most of this is boilerplate code that can be reused with simple changes.\n",
        "\n",
        "For training, we iterate over the datalaoder to get batches, and for each batch we do the following:\n",
        "\n",
        "- move each batch onto the specified device\n",
        "- perform a forward pass through the model to get the outputs\n",
        "- compute the loss based on the outputs and targets\n",
        "- compute the gradients via backpropagation\n",
        "- update the weights via the optimizer\n",
        "\n",
        "Certain layers, e.g. dropout, operate differently in training versus inference modes. To account for the same, we do:\n",
        "\n",
        "- model.train() to set all such layers to training mode\n",
        "- model.eval() to set all such layers to inference mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZBhXW-HhBh0"
      },
      "outputs": [],
      "source": [
        "def train(model, device, data_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    loss_train = 0\n",
        "    num_correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(data_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_train += loss.item()\n",
        "        prediction = output.argmax(dim=1)\n",
        "        num_correct += prediction.eq(target).sum().item()\n",
        "        if batch_idx % 50 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.4f}\\tAccuracy: {:.0f}%'.format(\n",
        "                epoch, batch_idx * len(data), len(data_loader.dataset),\n",
        "                100. * batch_idx / len(data_loader), loss_train / (batch_idx + 1),\n",
        "                100. * num_correct / (len(data) * (batch_idx + 1))))\n",
        "    loss_train /= len(data_loader)\n",
        "    accuracy = num_correct / len(data_loader.dataset)\n",
        "    return loss_train, accuracy\n",
        "\n",
        "\n",
        "def test(model, device, data_loader, criterion):\n",
        "    model.eval()\n",
        "    loss_test = 0\n",
        "    num_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss_test += loss.item()  # sum up batch loss\n",
        "            prediction = output.argmax(dim=1)\n",
        "            num_correct += prediction.eq(target).sum().item()\n",
        "    loss_test /= len(data_loader)\n",
        "    accuracy = num_correct / len(data_loader.dataset)\n",
        "    return loss_test, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sei6u0vshBh0"
      },
      "source": [
        "Now we put it all together:\n",
        "\n",
        "- Create the model\n",
        "- Set up the loss function (cross entropy)\n",
        "- Add an optimizer (in this case, Adam)\n",
        "- [Optional] Have a learning rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGnuaeYrhBh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994de998-33b6-4d63-a01b-6c46cf02133d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.3385\tAccuracy: 9%\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.4156\tAccuracy: 48%\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.1205\tAccuracy: 59%\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.9824\tAccuracy: 63%\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.9011\tAccuracy: 66%\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.8393\tAccuracy: 69%\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.7951\tAccuracy: 70%\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.7590\tAccuracy: 72%\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.7290\tAccuracy: 73%\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.7051\tAccuracy: 74%\n",
            "Epoch 1 Train: Loss: 0.6986, Accuracy: 73.920%\n",
            "\n",
            "Epoch 1 Test : Loss: 0.4422, Accuracy: 84.250%\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.4024\tAccuracy: 83%\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.4843\tAccuracy: 82%\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.4833\tAccuracy: 82%\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.4750\tAccuracy: 83%\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.4700\tAccuracy: 83%\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.4648\tAccuracy: 83%\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.4607\tAccuracy: 83%\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.4576\tAccuracy: 83%\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.4512\tAccuracy: 84%\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.4495\tAccuracy: 84%\n",
            "Epoch 2 Train: Loss: 0.4478, Accuracy: 83.698%\n",
            "\n",
            "Epoch 2 Test : Loss: 0.3503, Accuracy: 87.590%\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.4262\tAccuracy: 80%\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.4045\tAccuracy: 85%\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.4023\tAccuracy: 85%\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.4015\tAccuracy: 85%\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.4010\tAccuracy: 85%\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.4015\tAccuracy: 85%\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.3968\tAccuracy: 86%\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.3944\tAccuracy: 86%\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.3921\tAccuracy: 86%\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.3917\tAccuracy: 86%\n",
            "Epoch 3 Train: Loss: 0.3915, Accuracy: 85.718%\n",
            "\n",
            "Epoch 3 Test : Loss: 0.3207, Accuracy: 88.530%\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.2927\tAccuracy: 88%\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.3753\tAccuracy: 87%\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.3781\tAccuracy: 86%\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.3804\tAccuracy: 86%\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.3765\tAccuracy: 87%\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.3764\tAccuracy: 87%\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.3735\tAccuracy: 87%\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.3711\tAccuracy: 87%\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.3697\tAccuracy: 87%\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.3693\tAccuracy: 87%\n",
            "Epoch 4 Train: Loss: 0.3683, Accuracy: 86.688%\n",
            "\n",
            "Epoch 4 Test : Loss: 0.3047, Accuracy: 88.700%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 5):\n",
        "    loss_train, acc_train = train(model, device, dataloader_train, optimizer, criterion, epoch)\n",
        "    print('Epoch {} Train: Loss: {:.4f}, Accuracy: {:.3f}%\\n'.format(\n",
        "        epoch, loss_train, 100. * acc_train))\n",
        "    loss_test, acc_test = test(model, device, dataloader_test, criterion)\n",
        "    print('Epoch {} Test : Loss: {:.4f}, Accuracy: {:.3f}%\\n'.format(\n",
        "        epoch, loss_test, 100. * acc_test))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}