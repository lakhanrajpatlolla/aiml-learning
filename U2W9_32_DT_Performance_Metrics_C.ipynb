{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakhanrajpatlolla/aiml-learning/blob/master/U2W9_32_DT_Performance_Metrics_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFu_oj3E0jYc"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCG961D0xI44"
      },
      "source": [
        "### Learning Objective:\n",
        "\n",
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "*  understand the performance metrics using Decision tree classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzM6Pm7F5nmz",
        "cellView": "form"
      },
      "source": [
        "#@title Experiment Walkthrough Video\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<video width=\"420\" height=\"340\" controls>\n",
        "  <source src=\"https://cdn.exec.talentsprint.com/content/performance_metrics.mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbSKRbudra-i"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUiucdMtQQjV"
      },
      "source": [
        "### History\n",
        "\n",
        "Social network advertising, also social media targeting, is a group of terms that are used to describe forms of online advertising that focus on social networking services. One of the major benefits of this type of advertising is that advertisers can take advantage of the users’ demographic information and target their ads appropriately. Advantages are advertisers can reach users who are interested in their products, allows for detailed analysis and reporting, information gathered is real, not from statistical projections, does not access IP-addresses of the users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1nHORW_P2kH"
      },
      "source": [
        "### Description\n",
        "\n",
        "The dataset chosen for this  experiment is Social Network Ads. The dataset contains 400 records with 5 columns representing the below details.\n",
        "\n",
        "Data contains 5 columns:\n",
        "\n",
        "\n",
        "**UserID** - Each person has a unique ID from which we can identify the person uniquely.\n",
        "\n",
        "**Gender** - Person can be male or female.\n",
        "\n",
        "**Age** - Age of the person.\n",
        "\n",
        "**EstimatedSalary** - This column contains salary of a person.\n",
        "\n",
        "**Purchased** - Contains two numbers ‘0’ or ‘1’. ‘0’ means not purchased and ‘1’ means purchased. This variable is our target variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEzlYL4CDrmE"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import re\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"U2W9_32_DT_Performance_Metrics_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    from IPython.display import HTML, display\n",
        "    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/social_advertising.csv\")\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_inclass_mentor\": Mentor_support}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://learn-iiith.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getWalkthrough():\n",
        "  try:\n",
        "    if not Walkthrough:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Walkthrough\n",
        "  except NameError:\n",
        "    print (\"Please answer Walkthrough Question\")\n",
        "    return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9pFXqtfbcxG"
      },
      "source": [
        "### Importing required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ljIHCqCO3mk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUpWgHD8-4O3"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x4tygU7rw0u"
      },
      "source": [
        "#### Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_14Ruksx4zx"
      },
      "source": [
        "adv = pd.read_csv(\"social_advertising.csv\")\n",
        "adv.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEI1pkjtRTRx"
      },
      "source": [
        "adv = adv.drop([\"User ID\", \"Gender\"], axis = 1)\n",
        "adv.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md20bdLzGs9i"
      },
      "source": [
        "#### Extracting the features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_TiXrYCGqXx"
      },
      "source": [
        "X = adv.iloc[:, [0, 1]].values # Age and estimated salary\n",
        "y = adv.iloc[:, 2].values # Purchased"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz_y_tzzrxAZ"
      },
      "source": [
        "### Split the data into train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwmIhomc-igk"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j-ECM1T-i2p"
      },
      "source": [
        "print(X_train.shape, X_test.shape,y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONGTfqmxBBuw"
      },
      "source": [
        "### Model Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZqNg1ErQpt_"
      },
      "source": [
        "#### Training a Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmowAS_ePasE"
      },
      "source": [
        "clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\n",
        "# Fitting the data to the model\n",
        "clf.fit(X_train, y_train)\n",
        "# Get the predictions on the test dataset\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJQOOQpXQ2-m"
      },
      "source": [
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRZhKV_8hosC"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gq0o0s1hrEr"
      },
      "source": [
        "To evaluate the performance of a classification model, the following metrics are used:\n",
        "\n",
        "* Confusion matrix\n",
        "  * Accuracy\n",
        "  * Precision\n",
        "  * Recall\n",
        "  * F1-Score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erCaVXheUca3"
      },
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0spQOwVdl6r"
      },
      "source": [
        "* **Confusion matrix:**  is a table that is used to describe the performance of a classification model on a set of test data for which the true values are known.\n",
        "\n",
        "  * **true positive** The correct label of the given instance is positive, and the classifier also\n",
        "predicts it as a positive\n",
        "  * **false positive** The correct label is negative, but the classifier incorrectly predicts it as\n",
        "positive\n",
        "  * **true negative** The correct label is negative, and the classifier also predicts a negative\n",
        "  * **false negative** The correct label is positive, but the classifier incorrectly predicts it as\n",
        "negative\n",
        "\n",
        "* **Accuracy:** it is the ratio of the number of correct predictions to the total number of input samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4J9t7uyUbmX"
      },
      "source": [
        "# Creating a confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "fig, ax = plot_confusion_matrix(conf_mat=cm,cmap=plt.cm.RdPu)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quVva5nve6NE"
      },
      "source": [
        "#### Classification Report :\n",
        "\n",
        "A Classification report is used to measure the quality of predictions from a classification algorithm. More specifically, True Positives, False Positives, True negatives and False Negatives are used to predict the metrics of a classification report as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh50l0IOe_i5"
      },
      "source": [
        "print(classification_report(y_test, y_pred)) # support : The number of true instances for each class in the test set."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnKMEUwPiER0"
      },
      "source": [
        "#### Precision-Recall Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ_xgAFUiEeq"
      },
      "source": [
        "* **Precision:** The precision is calculated as the ratio between the number of Positive samples correctly classified to the total number of samples classified as Positive (either correctly or incorrectly)\n",
        "\n",
        "    Precision = $\\mathbf{\\frac{TruePositive}{TruePositive + FalsePositive}}$\n",
        "\n",
        "* **Recall:** Recall tells us how many true positives (points labelled as positive) were recalled or found by our model.\n",
        "\n",
        "   Recall = $\\mathbf{\\frac{TruePositive}{TruePositive + FalseNegative}}$\n",
        "\n",
        "* **F1-score:** precision and recall can be combined into a single score that seeks to balance both concerns, called the F-score or the F-measure.\n",
        "  \n",
        "   F1-score = $\\mathbf{\\frac{2*Precision*Recall}{Precision+Recall}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV0iHWlKbU5l"
      },
      "source": [
        "#### Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btDWhBYCDsf2"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "precision_score(y_test, y_pred, average=\"macro\")\n",
        "# High precision indicates a low number of false positives. Precision is important in scenarios where the cost of false positives is high."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHksJdbxXkv9"
      },
      "source": [
        "#### Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdMPEZlgXmUd"
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall_score(y_test, y_pred, average=\"macro\")\n",
        "# High recall indicates a low number of false negatives. Recall is important in scenarios where the cost of false negatives is high."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egDuWesgQxRw"
      },
      "source": [
        "####F1-score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMbjkrFd8fpj"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, y_pred, average=\"macro\")\n",
        "# The F1-score reaches its best value at 1 and worst at 0.\n",
        "# It is particularly useful when the class distribution is imbalanced, as it considers both false positives and false negatives."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4-oWiOAI7kZ"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvm-8H2RI7kd"
      },
      "source": [
        "#@title A model initially has given a precision of 80% and recall of 15%. After modifying the model, the precision is 70% and recall is 20%. Will the F1-Score be higher for the modified model compared to the initial model?  { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\",\"TRUE\", \"FALSE\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94dIhQKDI7kf"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKzGvfdyI7kg"
      },
      "source": [
        "#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Walkthrough = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OjkIq7II7kh"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwLT_C0vI7ki"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "gPMKJg_eI7kj"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}