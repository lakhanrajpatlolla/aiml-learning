{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakhanrajpatlolla/aiml-learning/blob/master/Lakhan_Hackathon2_Voice_E_commerce_Ordering_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZIubkln0AI2"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alui-GbzEBtW",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "c296bc45-9059-4581-c11d-50d3c26f1eb2"
      },
      "source": [
        "#@title Explanation Video\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<video width=\"854\" and height=\"480\" controls>\n",
        "  <source src=\"https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Walkthrough/Hackathon_Voice_based.mp4\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=\"854\" and height=\"480\" controls>\n",
              "  <source src=\"https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Walkthrough/Hackathon_Voice_based.mp4\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LNbxek40AI4"
      },
      "source": [
        "# Hackathon: Voice commands based E-commerce ordering system\n",
        "The goal of the hackathon is to train your model on different types of voice data (such as studio data and your own team data) and able to place order based on user preferences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fms7Yt7byCuQ"
      },
      "source": [
        "## Grading = 40 Marks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUtVl7cBHlIh"
      },
      "source": [
        "### **Objectives:**\n",
        "\n",
        "Stage 0 - Obtain Features from Audio samples\n",
        "\n",
        "Stage 1 (22 Marks) - Define and train a CNN model on Studio data and deploy the model in the server\n",
        "\n",
        "Stage 2 (18 Marks) - Collect your voice samples (team data) and refine the classifier trained on Studio_data. Deploy the model in the server."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYm_60PiPSsq"
      },
      "source": [
        "## Dataset Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiAu1XJx3lCJ"
      },
      "source": [
        "The data contains voice samples of classes - Zero, One, Two, Three, Four, Five. Each class is denoted by a numerical label from 0 to 5.\n",
        "\n",
        "The audio files collected in a Studio dataset contain very few noise samples and all the files are in wav format.\n",
        "\n",
        "The audio files recorded for the studio are saved with the following naming convention:\n",
        "\n",
        "● Class Representation + user_id + sample_ID (or noise + sample_ID)\n",
        "\n",
        "> For example: The voice sample by the user b2 recorded “Zero”, it is saved as 0_b2_35.wav. Here 35 is sample ID, 2 is the user id and ‘0’ is the label of that sample.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv0xxq_d0Qb_",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d9741b-b1df-4050-e6f1-3be4b1e5c03b"
      },
      "source": [
        "#@title Please run the setup to download the dataset\n",
        "\n",
        "from IPython import get_ipython\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"Hackathon2 - Voice E-commerce Ordering System\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Hackathon_data/B17_studio_rev_data.zip\")\n",
        "    ipython.magic(\"sx unzip B17_studio_rev_data.zip \")\n",
        "    print (\"Setup completed successfully\")\n",
        "\n",
        "setup()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqNBNvC25WNV"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import torch\n",
        "import librosa\n",
        "import warnings\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from time import sleep\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEg2PYXrOjnZ"
      },
      "source": [
        "## **Stage 0:** Obtain Features from Audio samples\n",
        "---\n",
        "\n",
        "### Generate features from an audio sample of '.wav' format\n",
        "- Code is available to extract the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTtb2zAj5k0-"
      },
      "source": [
        "# Caution: Do not change the default parameters\n",
        "def get_features(filepath, sr=8000, n_mfcc=30, n_mels=128, frames = 15):\n",
        "    # The following function contains code to produce features of the audio sample.\n",
        "    y, sr = librosa.load(filepath, sr=sr)\n",
        "    D = np.abs(librosa.stft(y))**2\n",
        "    S = librosa.feature.melspectrogram(S=D)\n",
        "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    log_S = librosa.power_to_db(S,ref=np.max)\n",
        "    features = librosa.feature.mfcc(S=log_S, n_mfcc=n_mfcc)\n",
        "    if features.shape[1] < frames :\n",
        "        features = np.hstack((features, np.zeros((n_mfcc, frames - features.shape[1]))))\n",
        "    elif features.shape[1] > frames:\n",
        "        features = features[:, :frames]\n",
        "\n",
        "    # Find 1st order delta_mfcc\n",
        "    delta1_mfcc = librosa.feature.delta(features, order=1)\n",
        "\n",
        "    # Find 2nd order delta_mfcc\n",
        "    delta2_mfcc = librosa.feature.delta(features, order=2)\n",
        "\n",
        "    # Stacking delta_mfcc features in sequence horizontally (column wise)\n",
        "    features = np.hstack((delta1_mfcc.flatten(), delta2_mfcc.flatten()))\n",
        "\n",
        "    # Increase the dimension by inserting an axis along second dimension\n",
        "    features = features.flatten()[:,np.newaxis]\n",
        "\n",
        "    # Convert the numpy.ndarray to a Tensor object\n",
        "    features = Variable(torch.from_numpy(features)).float()\n",
        "    return features"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhLFY4n6BwIj"
      },
      "source": [
        "All the voice samples needed for training are present in the folder `\"studio_data\"`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMF1AqHZhl1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "925002a2-b0e6-4287-dd6d-f1c300221126"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B17_studio_rev_data.zip  \u001b[0m\u001b[01;34msample_data\u001b[0m/  \u001b[01;34mstudio_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2AAbFp5KORl"
      },
      "source": [
        "##**Stage 1**:  Define and train a CNN model on Studio data and deploy the model in the server\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB-LowDuCMUL"
      },
      "source": [
        "### a) Extract features of Studio data (4 Marks)\n",
        "\n",
        " Load 'Studio data' and extract mfcc features\n",
        "\n",
        " **Evaluation Criteria:**\n",
        "\n",
        " * Complete the code in the load_data function\n",
        " * The function should take path of the folder containing audio samples as input\n",
        " * It should return features of all the audio samples present in the specified folder into single array (list of lists or 2-d numpy array) and their respective labels should be returned too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDzCa-532EUj"
      },
      "source": [
        "def load_data(folder_path):\n",
        "    #YOUR CODE HERE\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "      if filename.endswith(\".wav\"):\n",
        "        filepath = os.path.join(folder_path, filename)\n",
        "\n",
        "        #Extract features using get_features function\n",
        "        feature = get_features(filepath)\n",
        "        #conver features to a list before appending to features\n",
        "        features.append(feature.flatten().tolist())\n",
        "\n",
        "        #Extract label from filename prefix\n",
        "        #label = int(filename[0])\n",
        "        label = int(filename.split(\"_\")[0])\n",
        "        labels.append(label)\n",
        "\n",
        "    features = np.array(features)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Reshape features dynamically based on feature_dim\n",
        "    feature_dim = features.shape[1]  # Get the feature dimension\n",
        "    features = features.reshape(features.shape[0], feature_dim, 1)\n",
        "    print(\"Shape of the features: \", features.shape)\n",
        "    print(\"Shape of the labels: \", labels.shape)\n",
        "    return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7673ezpxFEfM"
      },
      "source": [
        "Load data from studio_data folder for extracting all features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5CjrlPVPjNs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b9bb403-62cb-49c4-fef1-388064396d82"
      },
      "source": [
        "studio_recorded_features, studio_recorded_labels = load_data('/content/studio_data')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the features:  (3979, 900, 1)\n",
            "Shape of the labels:  (3979,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the features: \", studio_recorded_features.shape)\n",
        "print(\"Shape of the labels: \", studio_recorded_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubGyPTFpf6Qo",
        "outputId": "0f41ebe7-ee70-464b-b183-ae9cd91d0b41"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the features:  (3979, 900, 1)\n",
            "Shape of the labels:  (3979,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krshAu69Hy8-"
      },
      "source": [
        "Use train_test_split for splitting the train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LV83ruiHvfO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# YOUR CODE HERE\n",
        "X_train, x_test, y_train, y_test = train_test_split(studio_recorded_features, studio_recorded_labels, test_size=0.2, random_state=42)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43M0H5Z23rnh"
      },
      "source": [
        "Load the dataset with DataLoader\n",
        "- Refer to [torch.utils.data.TensorDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset)\n",
        "- Refer to [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls6gI08XH2ak"
      },
      "source": [
        "# YOUR CODE HERE for the DataLoader\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train))\n",
        "test_data = TensorDataset(torch.from_numpy(x_test).float(), torch.from_numpy(y_test))\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGq6XpvhFynP"
      },
      "source": [
        "### b) Define your CNN architecture (4 Marks)\n",
        "\n",
        "[Hint](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU5hdERsFw5o",
        "cellView": "form"
      },
      "source": [
        "# @title Given Model Arch\n",
        "## Define your CNN Architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Sample Convolution Layer 1\n",
        "        self.conv1 = nn.Conv1d(in_channels=900, out_channels=400, kernel_size=1)\n",
        "        self.bn1 = nn.BatchNorm1d(400)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Sample Maxpool for the Convolutional Layer 1\n",
        "        self.maxpool1 = nn.MaxPool1d(1)\n",
        "\n",
        "        # Sample Dropout Layer\n",
        "        self.dropout = nn.Dropout(p=0.25)\n",
        "\n",
        "        # YOUR CODE HERE for defining more number of Convolutional layers with Maxpool as required (Hint: Use at least 2 more convolutional layers for better performance)\n",
        "\n",
        "\n",
        "        # YOUR CODE HERE for defining the Fully Connected Layer and also define LogSoftmax\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolution Layer 1, Maxpool and Dropout\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.maxpool1(out)\n",
        "        out = self.dropout(out)\n",
        "        # YOUR CODE HERE for the Convolutional Layers and Maxpool based on the defined Convolutional layers\n",
        "\n",
        "        # YOUR CODE HERE for flattening the output of the final pooling layer to a vector. Flattening is simply arranging the 3D volume of numbers into a 1D vector\n",
        "\n",
        "        # YOUR CODE HERE for returning the output of LogSoftmax after applying Fully Connected Layer"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class WavClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(WavClassifier, self).__init__()\n",
        "\n",
        "        # Layer 1: Convolution, Batch Normalization, ReLU, Max Pooling, Dropout\n",
        "        self.conv1 = nn.Conv1d(in_channels=900, out_channels=400, kernel_size=1, stride=1, padding = 0)  # Output channels: 400, Kernel size: 1\n",
        "        self.bn1 = nn.BatchNorm1d(400)\n",
        "        self.pool1 = nn.MaxPool1d(1)\n",
        "        self.dropout1 = nn.Dropout(p=0.25)\n",
        "\n",
        "        # Layer 2: Convolution, Batch Normalization, ReLU, Max Pooling, Dropout\n",
        "        self.conv2 = nn.Conv1d(in_channels=400, out_channels=256, kernel_size=3, stride=1, padding = 1)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.pool2 = nn.MaxPool1d(1)\n",
        "        self.dropout2 = nn.Dropout(p=0.25)\n",
        "\n",
        "        # Layer 3: Convolution, Batch Normalization, ReLU, Max Pooling, Dropout\n",
        "        self.conv3 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding = 1)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.pool3 = nn.MaxPool1d(1)\n",
        "        self.dropout3 = nn.Dropout(p=0.25)\n",
        "\n",
        "        # Fully connected layer:\n",
        "        self.fc = nn.Linear(128, num_classes)  # Adjust input size based on feature dimensions\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through convolutional layers\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        # Flatten and pass through fully connected layer\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        # Apply LogSoftmax\n",
        "        x = self.log_softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "4wYigUSUhxc7"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OFWuGmq05ZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7005ad8c-48e2-496f-9d9a-ffed671c4cdd"
      },
      "source": [
        "# To run the training on GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkt8lKQtCIWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a9debe9-82af-41d5-a19e-ee1f20a12773"
      },
      "source": [
        "model = WavClassifier()\n",
        "model = model.to(device)\n",
        "print(model)\n",
        "\n",
        "# #criterion = # YOUR CODE HERE : Explore and declare loss function\n",
        "# #optimizer = # YOUR CODE HERE : Explore on the optimizer and define with the learning rate\n",
        "# # Define loss function and optimizer\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adjust learning rate as needed"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WavClassifier(\n",
            "  (conv1): Conv1d(900, 400, kernel_size=(1,), stride=(1,))\n",
            "  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout1): Dropout(p=0.25, inplace=False)\n",
            "  (conv2): Conv1d(400, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool2): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout2): Dropout(p=0.25, inplace=False)\n",
            "  (conv3): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool3): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout3): Dropout(p=0.25, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=6, bias=True)\n",
            "  (log_softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5nF5pwKQ2t1"
      },
      "source": [
        "### c) Train and classify on the studio_data (3 Marks)\n",
        "\n",
        "The goal here is to train the Model on voice samples collected in studio data and validate it continuously to calculate the loss and accuracy for the train dataset across each epoch.\n",
        "\n",
        "Iterate over images in the train_loader and perform the following steps.\n",
        "\n",
        "1. First, zero out the gradients using zero_grad()\n",
        "\n",
        "2. Pass the data to the model. Convert the data to GPU before passing data  to the model\n",
        "\n",
        "3. Calculate the loss using a Loss function\n",
        "\n",
        "4. Perform Backward pass using backward() to update the weights\n",
        "\n",
        "5. Optimize and predict by using the torch.max()\n",
        "\n",
        "6. Calculate the accuracy of the train dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ot89MxKavVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "f8867481-4a08-417a-bba8-376153159a78"
      },
      "source": [
        "# @title Train Code Draft\n",
        "# YOUR CODE HERE. This will take time\n",
        "\n",
        "# Record loss and accuracy of the train dataset\n",
        "# Training loop\n",
        "num_epochs = 10  # Adjust the number of epochs as needed\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)  # Add channel dimension and move to device\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Calculate loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = 100 * correct_predictions / total_samples\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.3485, Accuracy: 48.32%\n",
            "Epoch 2/10, Loss: 0.8167, Accuracy: 71.91%\n",
            "Epoch 3/10, Loss: 0.6504, Accuracy: 77.79%\n",
            "Epoch 4/10, Loss: 0.5416, Accuracy: 81.34%\n",
            "Epoch 5/10, Loss: 0.4635, Accuracy: 84.20%\n",
            "Epoch 6/10, Loss: 0.4345, Accuracy: 84.35%\n",
            "Epoch 7/10, Loss: 0.3984, Accuracy: 86.11%\n",
            "Epoch 8/10, Loss: 0.3578, Accuracy: 87.59%\n",
            "Epoch 9/10, Loss: 0.3083, Accuracy: 89.26%\n",
            "Epoch 10/10, Loss: 0.2857, Accuracy: 90.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "def train_model(model, train_loader, num_epochs=10, learning_rate=0.001, device= device):\n",
        "    \"\"\"\n",
        "    Trains a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model: The PyTorch model to train.\n",
        "        train_loader: Train loader\n",
        "        num_epochs: Number of training epochs.\n",
        "        batch_size: Batch size for training.\n",
        "        learning_rate: Learning rate for the optimizer.\n",
        "        device: Device to use for training (\"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "        The trained model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Move model to the specified device\n",
        "    model.to(device)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        running_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Calculate loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Update weights\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_accuracy = 100 * correct_predictions / total_samples\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n",
        "    return model  # Return the trained model"
      ],
      "metadata": {
        "id": "D7-d5OsZV49K"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "studio_trained_model = train_model(model, train_loader, num_epochs=10, learning_rate=0.001, device= device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBOUroZDWlaf",
        "outputId": "eed0c9e8-a4f8-49ef-a398-57ef19e2fbfb"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.2055, Accuracy: 92.99%\n",
            "Epoch 2/10, Loss: 0.1693, Accuracy: 94.53%\n",
            "Epoch 3/10, Loss: 0.1566, Accuracy: 94.63%\n",
            "Epoch 4/10, Loss: 0.1505, Accuracy: 95.16%\n",
            "Epoch 5/10, Loss: 0.1476, Accuracy: 94.72%\n",
            "Epoch 6/10, Loss: 0.1391, Accuracy: 95.22%\n",
            "Epoch 7/10, Loss: 0.1297, Accuracy: 95.66%\n",
            "Epoch 8/10, Loss: 0.1066, Accuracy: 96.73%\n",
            "Epoch 9/10, Loss: 0.1139, Accuracy: 96.01%\n",
            "Epoch 10/10, Loss: 0.1086, Accuracy: 96.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5BJIQzgHa0k"
      },
      "source": [
        "### d) Testing Evaluation for CNN model (3 Marks)\n",
        "\n",
        "Evaluate model with the given test data\n",
        "\n",
        "1. Transform and load the test images.\n",
        "\n",
        "2. Pass the test data through the model (network) to get the outputs\n",
        "\n",
        "3. Get the predictions from a maximum value using torch.max\n",
        "\n",
        "4. Compare with the actual labels and get the count of the correct labels\n",
        "\n",
        "5. Calculate the accuracy based on the count of correct labels\n",
        "\n",
        "### **Expected testing accuracy is above 80%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnKZ-gP-30xR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "dca9331b-6b1f-4ca8-a704-dbcecc8ffe3f"
      },
      "source": [
        "# YOUR CODE HERE to test the model\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculations during evaluation\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total_samples += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct_predictions / total_samples\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        "\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 82.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the evaluation function\n",
        "studio_test_accuracy = evaluate_model(studio_trained_model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10b93LVtXOUB",
        "outputId": "b6f95ef2-d79b-4086-8c9d-41a4456a813b"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 83.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqIP3Y17byDq"
      },
      "source": [
        "### e) Save and download your model (2 Marks)\n",
        "\n",
        "**Save your model trained on studio data**\n",
        "\n",
        "* Save the state dictionary of the classifier (use pytorch only), It will be useful in\n",
        "integrating model to the web application\n",
        "\n",
        " [Hint](https://pytorch.org/tutorials/beginner/saving_loading_models.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7KAIpLsI4Uj"
      },
      "source": [
        "### YOUR CODE HERE for saving the CNN model\n",
        "torch.save(studio_trained_model.state_dict(), 'wav_classifier_model_studio_v1.pth')\n",
        "\n",
        "# Load the saved state dictionary\n",
        "#model.load_state_dict(torch.load('wav_classifier_model.pth'))"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsCHKXubHAJB"
      },
      "source": [
        "Download your trained model using the code below\n",
        "* Give the path of model file to download through the browser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDmWXfPaHJZG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "820d69f2-ec01-428d-b74e-01147a0754ad"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/wav_classifier_model_studio_v1.pth')"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_864a6114-4f4f-4934-ba5b-16ed74148ce9\", \"wav_classifier_model_studio_v1.pth\", 3088766)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl3Ins3vSTQx"
      },
      "source": [
        "### f) Deploy and evaluate your model trained on Studio Data in the server (6 Marks).\n",
        "\n",
        "(This can be done on the day of the Hackathon once the login username and password provided by the mentors in the lab)\n",
        "\n",
        "Deploy your model on the server, check the hackathon document (2-Server Access and File transfer For Voice based e-commerce ordering.pdf) for details.\n",
        "\n",
        "To order product in user interface, go through the document (3-Hackathon_II Application Interface Documentation.pdf) for details.\n",
        "\n",
        "\n",
        "**Evaluation Criteria: Four consecutive utterances should be predicted correctly by the model**\n",
        "\n",
        "- There are two stages in the e-commerce ordering application    \n",
        "    - Ordering Product\n",
        "    - Selecting the e-commerce platform\n",
        "- If both the stages are cleared as per the evaluation criteria you will get\n",
        "complete marks Otherwise, you will see a reduction in the marks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIXBC0aYKhKX"
      },
      "source": [
        "## **Stage 2:** Collect your voice samples and refine the classifier trained on studio_data and Team_data\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmSoJN11_kMR"
      },
      "source": [
        "### a) Collect your Team Voice Samples and extract features (6 Marks)\n",
        "\n",
        "(This can be done on the day of the Hackathon once the login username and password is given by mentors in the lab)\n",
        "\n",
        "* In order to collect the team data, ensure the server is active (2-Server Access and File transfer For Voice based e-commerce ordering.pdf)\n",
        "\n",
        "* Refer document \"3-Hackathon_II Application Interface Documentation.pdf\" for collecting your team voice samples. These will get stored in your server\n",
        "\n",
        "**Evaluation Criteria:**\n",
        "* Load 'Team_data' and extract features\n",
        "* Combine features of team data with the extracted features of studio data\n",
        "* Split the combined features into train and test data\n",
        "* Load the dataset with DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv3I24flWlLq"
      },
      "source": [
        "!mkdir team_data"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB_bSllKWJ5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f1d88e-a71b-40d1-d483-f8c0d3d16654"
      },
      "source": [
        "# Replace <YOUR_GROUP_ID> with your Username given in the lab\n",
        "!wget -r -A .wav https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/ -nH --cut-dirs=100  -P ./team_data"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-14 11:04:46--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/\n",
            "Resolving aiml-sandbox1.talentsprint.com (aiml-sandbox1.talentsprint.com)... 139.162.203.12\n",
            "Connecting to aiml-sandbox1.talentsprint.com (aiml-sandbox1.talentsprint.com)|139.162.203.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./team_data/index.html.tmp’\n",
            "\n",
            "index.html.tmp          [ <=>                ]   5.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:46 (711 MB/s) - ‘./team_data/index.html.tmp’ saved [5320]\n",
            "\n",
            "Loading robots.txt; please ignore errors.\n",
            "--2025-03-14 11:04:46--  https://aiml-sandbox1.talentsprint.com/robots.txt\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-03-14 11:04:46 ERROR 404: Not Found.\n",
            "\n",
            "Removing ./team_data/index.html.tmp since it should be rejected.\n",
            "\n",
            "--2025-03-14 11:04:46--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-03-14 11:04:46 ERROR 404: Not Found.\n",
            "\n",
            "--2025-03-14 11:04:46--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/0_b24h3g12_1741949858.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 65624 (64K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/0_b24h3g12_1741949858.wav’\n",
            "\n",
            "0_b24h3g12_17419498 100%[===================>]  64.09K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-03-14 11:04:47 (549 KB/s) - ‘./team_data/0_b24h3g12_1741949858.wav’ saved [65624/65624]\n",
            "\n",
            "--2025-03-14 11:04:47--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/0_b24h3g12_1741950062.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/0_b24h3g12_1741950062.wav’\n",
            "\n",
            "0_b24h3g12_17419500 100%[===================>]  88.09K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-03-14 11:04:47 (757 KB/s) - ‘./team_data/0_b24h3g12_1741950062.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:47--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/0_b24h3g12_1741950135.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/0_b24h3g12_1741950135.wav’\n",
            "\n",
            "0_b24h3g12_17419501 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:47 (224 MB/s) - ‘./team_data/0_b24h3g12_1741950135.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:47--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/0_b24h3g12_1741950207.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/0_b24h3g12_1741950207.wav’\n",
            "\n",
            "0_b24h3g12_17419502 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:47 (263 MB/s) - ‘./team_data/0_b24h3g12_1741950207.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:47--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/0_b24h3test01_1741083250.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/0_b24h3test01_1741083250.wav’\n",
            "\n",
            "0_b24h3test01_17410 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:47 (257 MB/s) - ‘./team_data/0_b24h3test01_1741083250.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:47--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/0_b24h3test04_1741082468.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/0_b24h3test04_1741082468.wav’\n",
            "\n",
            "0_b24h3test04_17410 100%[===================>]  88.09K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-03-14 11:04:47 (171 MB/s) - ‘./team_data/0_b24h3test04_1741082468.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:47--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/0_b24h3test04_1741082655.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/0_b24h3test04_1741082655.wav’\n",
            "\n",
            "0_b24h3test04_17410 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:48 (218 MB/s) - ‘./team_data/0_b24h3test04_1741082655.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:48--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/1_b24h3g12_1741949892.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/1_b24h3g12_1741949892.wav’\n",
            "\n",
            "1_b24h3g12_17419498 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:48 (204 MB/s) - ‘./team_data/1_b24h3g12_1741949892.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:48--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/1_b24h3g12_1741950078.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/1_b24h3g12_1741950078.wav’\n",
            "\n",
            "1_b24h3g12_17419500 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:48 (238 MB/s) - ‘./team_data/1_b24h3g12_1741950078.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:48--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/1_b24h3g12_1741950144.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/1_b24h3g12_1741950144.wav’\n",
            "\n",
            "1_b24h3g12_17419501 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:48 (290 MB/s) - ‘./team_data/1_b24h3g12_1741950144.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:48--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/1_b24h3g12_1741950215.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/1_b24h3g12_1741950215.wav’\n",
            "\n",
            "1_b24h3g12_17419502 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:48 (232 MB/s) - ‘./team_data/1_b24h3g12_1741950215.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:48--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/1_b24h3test01_1741083265.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/1_b24h3test01_1741083265.wav’\n",
            "\n",
            "1_b24h3test01_17410 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:48 (235 MB/s) - ‘./team_data/1_b24h3test01_1741083265.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:48--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/1_b24h3test04_1741082475.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/1_b24h3test04_1741082475.wav’\n",
            "\n",
            "1_b24h3test04_17410 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:48 (305 MB/s) - ‘./team_data/1_b24h3test04_1741082475.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:48--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/1_b24h3test04_1741082666.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/1_b24h3test04_1741082666.wav’\n",
            "\n",
            "1_b24h3test04_17410 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:48 (286 MB/s) - ‘./team_data/1_b24h3test04_1741082666.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:48--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/2_b24h3g12_1741949912.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/2_b24h3g12_1741949912.wav’\n",
            "\n",
            "2_b24h3g12_17419499 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:49 (259 MB/s) - ‘./team_data/2_b24h3g12_1741949912.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:49--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/2_b24h3g12_1741950087.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/2_b24h3g12_1741950087.wav’\n",
            "\n",
            "2_b24h3g12_17419500 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:49 (244 MB/s) - ‘./team_data/2_b24h3g12_1741950087.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:49--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/2_b24h3g12_1741950152.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/2_b24h3g12_1741950152.wav’\n",
            "\n",
            "2_b24h3g12_17419501 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:49 (218 MB/s) - ‘./team_data/2_b24h3g12_1741950152.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:49--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/2_b24h3g12_1741950227.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/2_b24h3g12_1741950227.wav’\n",
            "\n",
            "2_b24h3g12_17419502 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:49 (236 MB/s) - ‘./team_data/2_b24h3g12_1741950227.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:49--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/2_b24h3test01_1741083276.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/2_b24h3test01_1741083276.wav’\n",
            "\n",
            "2_b24h3test01_17410 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:49 (234 MB/s) - ‘./team_data/2_b24h3test01_1741083276.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:49--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/2_b24h3test04_1741082483.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/2_b24h3test04_1741082483.wav’\n",
            "\n",
            "2_b24h3test04_17410 100%[===================>]  88.09K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-03-14 11:04:49 (150 MB/s) - ‘./team_data/2_b24h3test04_1741082483.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:49--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/2_b24h3test04_1741082674.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/2_b24h3test04_1741082674.wav’\n",
            "\n",
            "2_b24h3test04_17410 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:49 (229 MB/s) - ‘./team_data/2_b24h3test04_1741082674.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:49--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/3_b24h3g12_1741949928.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/3_b24h3g12_1741949928.wav’\n",
            "\n",
            "3_b24h3g12_17419499 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:49 (222 MB/s) - ‘./team_data/3_b24h3g12_1741949928.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:49--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/3_b24h3g12_1741950101.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/3_b24h3g12_1741950101.wav’\n",
            "\n",
            "3_b24h3g12_17419501 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:49 (221 MB/s) - ‘./team_data/3_b24h3g12_1741950101.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:49--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/3_b24h3g12_1741950161.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/3_b24h3g12_1741950161.wav’\n",
            "\n",
            "3_b24h3g12_17419501 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:50 (221 MB/s) - ‘./team_data/3_b24h3g12_1741950161.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:50--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/3_b24h3g12_1741950239.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/3_b24h3g12_1741950239.wav’\n",
            "\n",
            "3_b24h3g12_17419502 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:50 (239 MB/s) - ‘./team_data/3_b24h3g12_1741950239.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:50--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/3_b24h3test01_1741083281.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/3_b24h3test01_1741083281.wav’\n",
            "\n",
            "3_b24h3test01_17410 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:50 (284 MB/s) - ‘./team_data/3_b24h3test01_1741083281.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:50--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/3_b24h3test04_1741082497.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/3_b24h3test04_1741082497.wav’\n",
            "\n",
            "3_b24h3test04_17410 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:50 (245 MB/s) - ‘./team_data/3_b24h3test04_1741082497.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:50--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/4_b24h3g12_1741949946.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/4_b24h3g12_1741949946.wav’\n",
            "\n",
            "4_b24h3g12_17419499 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:50 (231 MB/s) - ‘./team_data/4_b24h3g12_1741949946.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:50--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/4_b24h3g12_1741950110.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/4_b24h3g12_1741950110.wav’\n",
            "\n",
            "4_b24h3g12_17419501 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:50 (269 MB/s) - ‘./team_data/4_b24h3g12_1741950110.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:50--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/4_b24h3g12_1741950171.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/4_b24h3g12_1741950171.wav’\n",
            "\n",
            "4_b24h3g12_17419501 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:50 (218 MB/s) - ‘./team_data/4_b24h3g12_1741950171.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:50--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/4_b24h3g12_1741950247.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/4_b24h3g12_1741950247.wav’\n",
            "\n",
            "4_b24h3g12_17419502 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:50 (237 MB/s) - ‘./team_data/4_b24h3g12_1741950247.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:50--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/4_b24h3test01_1741083286.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/4_b24h3test01_1741083286.wav’\n",
            "\n",
            "4_b24h3test01_17410 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:51 (243 MB/s) - ‘./team_data/4_b24h3test01_1741083286.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:51--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/4_b24h3test04_1741082505.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/4_b24h3test04_1741082505.wav’\n",
            "\n",
            "4_b24h3test04_17410 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:51 (255 MB/s) - ‘./team_data/4_b24h3test04_1741082505.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:51--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/5_b24h3g12_1741949962.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/5_b24h3g12_1741949962.wav’\n",
            "\n",
            "5_b24h3g12_17419499 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:51 (242 MB/s) - ‘./team_data/5_b24h3g12_1741949962.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:51--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/5_b24h3g12_1741950121.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/5_b24h3g12_1741950121.wav’\n",
            "\n",
            "5_b24h3g12_17419501 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:51 (220 MB/s) - ‘./team_data/5_b24h3g12_1741950121.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:51--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/5_b24h3g12_1741950186.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/5_b24h3g12_1741950186.wav’\n",
            "\n",
            "5_b24h3g12_17419501 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:51 (343 MB/s) - ‘./team_data/5_b24h3g12_1741950186.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:51--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/5_b24h3g12_1741950256.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/5_b24h3g12_1741950256.wav’\n",
            "\n",
            "5_b24h3g12_17419502 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:51 (311 MB/s) - ‘./team_data/5_b24h3g12_1741950256.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:51--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/5_b24h3test01_1741083290.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/5_b24h3test01_1741083290.wav’\n",
            "\n",
            "5_b24h3test01_17410 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:51 (231 MB/s) - ‘./team_data/5_b24h3test01_1741083290.wav’ saved [90200/90200]\n",
            "\n",
            "--2025-03-14 11:04:51--  https://aiml-sandbox1.talentsprint.com/audio_recorder/b24h3g12/team_data/5_b24h3test04_1741082509.wav\n",
            "Reusing existing connection to aiml-sandbox1.talentsprint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90200 (88K) [application/octet-stream]\n",
            "Saving to: ‘./team_data/5_b24h3test04_1741082509.wav’\n",
            "\n",
            "5_b24h3test04_17410 100%[===================>]  88.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-14 11:04:51 (321 MB/s) - ‘./team_data/5_b24h3test04_1741082509.wav’ saved [90200/90200]\n",
            "\n",
            "FINISHED --2025-03-14 11:04:51--\n",
            "Total wall clock time: 5.8s\n",
            "Downloaded: 40 files, 3.3M in 0.2s (13.5 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G17PFkgI02J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f21bf53-5fea-440b-a673-c978ae0bde6d"
      },
      "source": [
        "# YOUR CODE HERE to Load data from teamdata folder for extracting all features and labels\n",
        "team_data_recorded_features, team_data_recorded_labels = load_data('/content/team_data')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the features:  (39, 900, 1)\n",
            "Shape of the labels:  (39,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_sh6DCbJKhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e20aa052-520c-4537-b60d-8f5383fbba1d"
      },
      "source": [
        "# Combine the features of all voice samples (studio_data and teamdata)\n",
        "# YOUR CODE HERE\n",
        "# 1. Combine features using numpy.concatenate\n",
        "combined_features = np.concatenate((studio_recorded_features, team_data_recorded_features), axis=0)\n",
        "\n",
        "# 2. Combine labels using numpy.concatenate\n",
        "combined_labels = np.concatenate((studio_recorded_labels, team_data_recorded_labels), axis=0)\n",
        "\n",
        "# Print shapes to verify\n",
        "print(\"Combined features shape:\", combined_features.shape)\n",
        "print(\"Combined labels shape:\", combined_labels.shape)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined features shape: (4018, 900, 1)\n",
            "Combined labels shape: (4018,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcSfoU9hyst4"
      },
      "source": [
        "# YOUR CODE HERE to split the combined features into train and test data (Hint: Use train_test_split)\n",
        "from sklearn.model_selection import train_test_split\n",
        "# YOUR CODE HERE\n",
        "X_train_combined, x_test_combined, y_train_combined, y_test_combined = train_test_split(combined_features, combined_labels, test_size=0.2, random_state=42)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ8gSTYg1dSp"
      },
      "source": [
        "# YOUR CODE HERE to load the dataset with DataLoader\n",
        "\n",
        "train_data_combined = TensorDataset(torch.from_numpy(X_train_combined).float(), torch.from_numpy(y_train_combined))\n",
        "test_data_combined = TensorDataset(torch.from_numpy(x_test_combined).float(), torch.from_numpy(y_test_combined))\n",
        "\n",
        "batch_size = 64\n",
        "train_loader_combined = DataLoader(train_data_combined, shuffle=True, batch_size=batch_size)\n",
        "test_loader_combined = DataLoader(test_data_combined, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSE9E9mDF7Az"
      },
      "source": [
        "### b) Classify and download the model (6 Marks)\n",
        "\n",
        "The goal here is to train and test your model on all voice samples collected in studio and team data\n",
        "\n",
        "**Evaluation Criteria:**\n",
        "* Refine your classifier (if needed)\n",
        "* Train your model on the extracted train data\n",
        "* Test your model on the extracted test data\n",
        "* Save and download the trained model\n",
        "\n",
        "### **Expected testing accuracy is above 80%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1EtSEwDG-q4"
      },
      "source": [
        "# YOUR CODE HERE for refining your classifier (if needed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz0UbGJrz59Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf64471b-984e-4aa1-87ec-a27417232396"
      },
      "source": [
        "# YOUR CODE HERE to train your model\n",
        "\n",
        "# Record loss and accuracy of the train dataset\n",
        "combined_trained_model = train_model(model, train_loader_combined, num_epochs=10, learning_rate=0.001, device= device)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.2585, Accuracy: 92.81%\n",
            "Epoch 2/10, Loss: 0.1904, Accuracy: 93.40%\n",
            "Epoch 3/10, Loss: 0.1777, Accuracy: 94.90%\n",
            "Epoch 4/10, Loss: 0.1498, Accuracy: 95.30%\n",
            "Epoch 5/10, Loss: 0.1730, Accuracy: 94.34%\n",
            "Epoch 6/10, Loss: 0.1430, Accuracy: 95.49%\n",
            "Epoch 7/10, Loss: 0.1650, Accuracy: 94.28%\n",
            "Epoch 8/10, Loss: 0.1399, Accuracy: 95.58%\n",
            "Epoch 9/10, Loss: 0.1188, Accuracy: 95.96%\n",
            "Epoch 10/10, Loss: 0.1088, Accuracy: 96.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CkqFppJ0Fha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc005eec-2c10-4f9a-928d-dfa06d8fb6dc"
      },
      "source": [
        "from math import comb\n",
        "# YOUR CODE HERE to test your model\n",
        "combined_test_accuracy = evaluate_model(combined_trained_model, test_loader_combined, device)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 92.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snSilDehQcKv"
      },
      "source": [
        "**Save your trained model**\n",
        "\n",
        "* Save the state dictionary of the classifier (use pytorch only), It will be useful in\n",
        "integrating model to the web application\n",
        "\n",
        " [Hint](https://pytorch.org/tutorials/beginner/saving_loading_models.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGiaYmCnQcKz"
      },
      "source": [
        "### YOUR CODE HERE for saving the CNN model\n",
        "torch.save(combined_trained_model.state_dict(), 'wav_classifier_model_combined_v1.pth')"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TSFyHRFQcK1"
      },
      "source": [
        "Download your trained model using the code below\n",
        "* Give the path of model file to download through the browser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF2kGMjAQcK2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "cb15b128-79f1-4d73-fd84-7c1da3548328"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/wav_classifier_model_combined_v1.pth')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b648d6a1-0bf3-4f43-a019-749b5b7983f6\", \"wav_classifier_model_combined_v1.pth\", 3088820)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfhmbXkFx6is"
      },
      "source": [
        "### c) Deploy and evaluate your model trained on Studio Data + Team Data in the server (6 Marks).\n",
        "\n",
        "(This can be done on the day of the Hackathon once the login username and password provided by the mentors in the lab)\n",
        "\n",
        "Deploy your model on the server, check the hackathon document (2-Server Access and File transfer For Voice based e-commerce ordering.pdf) for details.\n",
        "\n",
        "To order product in user interface, go through the document (3-Hackathon_II Application Interface Documentation.pdf) for details.\n",
        "\n",
        "\n",
        "**Evaluation Criteria: Four consecutive utterances should be predicted correctly by the model**\n",
        "\n",
        "- There are two stages in the e-commerce ordering application    \n",
        "    - Ordering Product\n",
        "    - Selecting the e-commerce platform\n",
        "- If both the stages are cleared as per the evaluation criteria you will get\n",
        "complete marks Otherwise, you will see a reduction in the marks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kIo3R5hQnrh"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}