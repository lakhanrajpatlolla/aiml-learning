{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakhanrajpatlolla/aiml-learning/blob/master/Transfer_Learning_Pre_trained_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE25tajukfbs"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint\n",
        "## Not for grading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSvlKHJ05pQd"
      },
      "source": [
        "## Setup Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t-K9H-B5pQe"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_CGILrZ5pQe"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "EFYcjfU65pQe"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"Transfer_Learning_Pre_trained_Models\" #name of the notebook\n",
        "Answer = \"Ungraded\"\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    from IPython.display import HTML, display\n",
        "    ipython.magic(\"sx wget -qq https://cdn.iiith.talentsprint.com/aiml/mvsr/Cat_Dog_data.zip\")\n",
        "    ipython.magic(\"sx unzip -qq Cat_Dog_data.zip\")\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getComplexity() and getAdditional() and getConcepts() and getComments():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"feedback_experiments_input\" : Comments, \"notebook\" : notebook}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://learn-iiith.talentsprint.com/notebook_submissions\")\n",
        "        # print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "      return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn2KjKgkh5SB"
      },
      "source": [
        "## Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQEM-SqyRz5C"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "from torchvision import datasets, transforms, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfXKLScafCPx"
      },
      "outputs": [],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLH7FPZGfOfq"
      },
      "outputs": [],
      "source": [
        "(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYUacQzmUgAu"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfcyu5P2f0v3"
      },
      "source": [
        "## **AlexNet**\n",
        "\n",
        "\n",
        "AlexNet was the first convolutional network built for image classification\n",
        "\n",
        "1.      AlexNet architecture consists of 5 convolutional layers, 3 max-pooling layers, 2 normalization layers, 2 fully connected layers, and 1 softmax layer.\n",
        "\n",
        "2.      Each convolutional layer consists of convolutional filters and a nonlinear activation function ReLU.\n",
        "\n",
        "3.      The pooling layers are used to perform max pooling.\n",
        "\n",
        "4.      Input size is fixed due to the presence of fully connected layers.\n",
        "\n",
        "5.      The input size is mentioned at most of the places as 224x224x3.\n",
        "\n",
        "6.      AlexNet overall has nearly 60 million parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pUPuO8_gADw"
      },
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0l6isBYp0He"
      },
      "source": [
        "### **Auto-Transform : Pre-processsing specific of pre-trained model Automatically**\n",
        "\n",
        "### Step 1: Load the weights to the existing model\n",
        "\n",
        "### Step 2: Initialize the inference transforms\n",
        "\n",
        "\n",
        "### Step 3: Apply inference preprocessing transforms\n",
        "\n",
        "\n",
        "[Link](https://pytorch.org/vision/stable/models.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyY6pxK91O_g"
      },
      "source": [
        "### Auto transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o5b3NkO1Ojo"
      },
      "outputs": [],
      "source": [
        "weights = models.AlexNet_Weights.IMAGENET1K_V1.DEFAULT # Best avilable weights\n",
        "auto_transforms= weights.transforms()\n",
        "print(auto_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g1h2Nzl0vZd"
      },
      "source": [
        "### Manual Transform\n",
        "[How to normalize image data](https://saturncloud.io/blog/how-to-normalize-image-dataset-using-pytorch/#:~:text=Image%20normalization%20is%20the%20process,dividing%20by%20the%20standard%20deviation.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iJ7kBcT0sdF"
      },
      "outputs": [],
      "source": [
        "normalize=transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229,0.224, 0.225])\n",
        "manual_transform = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(), normalize,]) # transforms.InterpolationMode.BILINEAR,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TszAkBoYg3Rj"
      },
      "source": [
        "### Implementing on the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GTj8d1LDMtZ"
      },
      "outputs": [],
      "source": [
        "#transform = transforms.Compose([transforms.Resize((224, 224)),transforms.ToTensor(),])\n",
        "\n",
        "# Prepare the train and test data\n",
        "data_dir = '/content/Cat_Dog_data'\n",
        "trainset = datasets.ImageFolder(data_dir + '/train', transform=manual_transform) #manual_transform # auto_transforms\n",
        "testset = datasets.ImageFolder(data_dir + '/test', transform=manual_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4z4ipdTg8Pi"
      },
      "outputs": [],
      "source": [
        "dataset_sizes = {'Train': len(trainset), 'Test': len(testset)}\n",
        "dataset_sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h155HT7XAzo8"
      },
      "outputs": [],
      "source": [
        "# class_to_idx gives the dictionary mapping of the classname to the index (label)\n",
        "label_name = trainset.class_to_idx\n",
        "print(label_name)\n",
        "\n",
        "# To get class names  trainset.classes\n",
        "class_name = trainset.classes\n",
        "print(class_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_lBk0u-TLks"
      },
      "outputs": [],
      "source": [
        "# Load the data. utils.dataloader. Itis a package for loading the dataset\n",
        "train_loader = torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=100)\n",
        "test_loader = torch.utils.data.DataLoader(testset, shuffle=False, batch_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUY6Kr4ap97A"
      },
      "outputs": [],
      "source": [
        "for batch in iter(train_loader):\n",
        "  print(batch[0].shape, batch[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-k5fa77EUKZL"
      },
      "outputs": [],
      "source": [
        "# Get the images and the labels\n",
        "current_Images, current_labels = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypGmvT7yN-lQ"
      },
      "source": [
        "### Plotting the sample images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AF-IaO1xUmLk"
      },
      "outputs": [],
      "source": [
        "current_Images[10].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghe0nVqAKTl5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(current_Images[10].permute(1,2,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YR-ehIo7VGya"
      },
      "outputs": [],
      "source": [
        "# The label of the current image\n",
        "current_labels[10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r0oDI5q1w55"
      },
      "source": [
        "### **Older way of doing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzS9j0i3R6_m"
      },
      "outputs": [],
      "source": [
        "# model_alexnet = models.alexnet(pretrained = True) # Architecture and weights are downloaded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ7xseUUM9mL"
      },
      "source": [
        "### **Updated way of doing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdQ3RGhiM87U"
      },
      "outputs": [],
      "source": [
        "#weights = models.AlexNet_Weights.IMAGENET1K_V1.DEFAULT # Best avilable weights\n",
        "#auto_transforms= weights.transforms()\n",
        "#print(auto_transforms)\n",
        "#print(weights)\n",
        "model_alexnet = models.alexnet(weights=weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV41RysvEkw8"
      },
      "outputs": [],
      "source": [
        "print(model_alexnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QL7lBPepjHb2"
      },
      "outputs": [],
      "source": [
        "pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5i4CS3DjO-_"
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNQyIWO0jUA_"
      },
      "outputs": [],
      "source": [
        "summary(model_alexnet, input_size=(1, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMb-Miw3kLvy"
      },
      "source": [
        "### Getting Feature Learning and Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvNAhSSZLWMz"
      },
      "outputs": [],
      "source": [
        "model_alexnet.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1RmaHTO4aXr"
      },
      "outputs": [],
      "source": [
        "model_alexnet.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKsVfUgpLmbL"
      },
      "outputs": [],
      "source": [
        "# Getting all bias and weights\n",
        "for param in model_alexnet.features.parameters():\n",
        "  print(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFy90MLOW8u5"
      },
      "outputs": [],
      "source": [
        "# Freezing all Trainable parameters\n",
        "for param in model_alexnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# For unfeezing all weights, give param.requires_grad = True\n",
        "#for param in model_alexnet.parameters():\n",
        "#    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMVUg_uMWfXY"
      },
      "outputs": [],
      "source": [
        "# Changing last layer\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "model_alexnet.classifier[6] = nn.Linear(4096, 2)\n",
        "model_alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN7tp0QPV6qJ"
      },
      "outputs": [],
      "source": [
        "model_alexnet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBimBcLKOiC9"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "summary(model_alexnet, (3, 224,224))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZBr6vHNVvDt"
      },
      "source": [
        "### Train the model using AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FSGeeM2R6zw"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train only the last layer\n",
        "optimizer = optim.Adam([ {'params': model_alexnet.classifier[6].parameters()}], lr=1e-4)\n",
        "\n",
        "# Uncomment this to train all parameters\n",
        "#optimizer = optim.Adam(model_alexnet.parameters(), lr=  1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGpDXo3mFy4C"
      },
      "outputs": [],
      "source": [
        "# No of Epochs\n",
        "epoch = 5\n",
        "\n",
        "# Keeping the network in train mode\n",
        "model_alexnet.train()\n",
        "train_losses,  train_accuracy = [], []\n",
        "\n",
        "# Loop for no of epochs\n",
        "for e in range(epoch):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    # Iterate through all the batches in each epoch\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "      # Convert the image and label to gpu for faster execution\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Passing the data to the model (Forward Pass)\n",
        "      outputs = model_alexnet(images)\n",
        "\n",
        "      # Calculating the loss\n",
        "      loss = criterion(outputs, labels)\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      # Zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Performing backward pass (Backpropagation)\n",
        "      loss.backward()\n",
        "\n",
        "      # optimizer.step() updates the weights accordingly\n",
        "      optimizer.step()\n",
        "\n",
        "      # Accuracy calculation\n",
        "      _, predicted = torch.max(outputs, 1) #_, => stores all the index of the maximum output\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_losses.append(train_loss/len(trainset))\n",
        "    train_accuracy.append(100 * correct/len(trainset))\n",
        "    print('epoch: {}, Train Loss:{:.6f} Train Accuracy: {:.2f} '.format(e+1,train_losses[-1], train_accuracy[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isso1axbgQaW"
      },
      "source": [
        "### Test the Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Hbqt6i5JOJ0"
      },
      "outputs": [],
      "source": [
        "model_alexnet.eval()\n",
        "\n",
        "image = current_Images[10]\n",
        "\n",
        "# Add an extra batch dimension since pytorch treats all images as batches\n",
        "output = model_alexnet(image.unsqueeze(0).to(device))\n",
        "\n",
        "_, predicted = torch.max(output, 1)\n",
        "\n",
        "trainset.classes[predicted.item()], predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPbbmRkBR6xC"
      },
      "outputs": [],
      "source": [
        "# Keeping the network in evaluation mode\n",
        "model_alexnet.eval()\n",
        "\n",
        "Test_accuracy = 0\n",
        "predictions, test_images = [], []\n",
        "# Iterate through all the batches in each epoch\n",
        "for images,labels in test_loader:\n",
        "    # Convert the images and labels to gpu for faster execution\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Do the forward pass\n",
        "    outputs = model_alexnet(images)\n",
        "\n",
        "    # Accuracy calculation\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    Test_accuracy += (predicted == labels).sum().item()\n",
        "    test_images.extend(images.cpu())\n",
        "    predictions.extend(predicted.cpu())\n",
        "\n",
        "Accuracy = Test_accuracy / len(testset)\n",
        "print(\"Accuracy of Test Data is\", Accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxoLshRb6reA"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 4, figsize = (6,6))\n",
        "axes = axes.reshape(-1)\n",
        "import numpy as np\n",
        "for i in np.arange(0, len(test_images)):\n",
        "    axes[i].imshow(test_images[i].permute(1, 2, 0))\n",
        "    axes[i].set_title(predictions[i])\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfNRLzlEMxsq"
      },
      "source": [
        "## VGG16\n",
        "\n",
        "Reference for update :\n",
        "\n",
        "     weights = models.AlexNet_Weights.IMAGENET1K_V1.DEFAULT # Best avilable weights\n",
        "\n",
        "     auto_transforms= weights.transforms()\n",
        "\n",
        "     print(auto_transforms)\n",
        "\n",
        "     print(weights)\n",
        "\n",
        "**Update below impelmentation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef7s2JoTMzUI"
      },
      "outputs": [],
      "source": [
        "# Load the pretrained model\n",
        "model_vgg16 = models.vgg16(pretrained=True) # Old way of doing\n",
        "print(model_vgg16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m1dCN1nHKAW"
      },
      "outputs": [],
      "source": [
        "# Freezing all weights\n",
        "for param in model_vgg16.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4XS5NY686c-"
      },
      "outputs": [],
      "source": [
        "model_vgg16.features[28]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gxekm7Ry9-Ui"
      },
      "outputs": [],
      "source": [
        "model_vgg16.classifier[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5y3BGFIAB-X"
      },
      "outputs": [],
      "source": [
        "model_vgg16.classifier[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_4eJ7eWM8W4"
      },
      "outputs": [],
      "source": [
        "# Change last 2 layers\n",
        "model_vgg16.classifier[3] = nn.Linear(4096, 1048)\n",
        "\n",
        "model_vgg16.classifier[6] = nn.Linear(1048, 2)\n",
        "model_vgg16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q5lo-uhbJ7P"
      },
      "outputs": [],
      "source": [
        "model_vgg16.to(device)\n",
        "summary(model_vgg16, (3, 224,224)) # Last layer parameters not frozen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tttIeWmUJ_GA"
      },
      "outputs": [],
      "source": [
        "# To update parameters of few layers  # {'params': model_vgg16.features[28].parameters()},\n",
        "optimizer1 = optim.SGD([\n",
        "    {'params': model_vgg16.classifier[3].parameters()},\n",
        "      {'params': model_vgg16.classifier[6].parameters(), 'lr': 1e-2}\n",
        "    ], lr=1e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd6Mv25WDS74"
      },
      "outputs": [],
      "source": [
        "# No of Epochs\n",
        "epoch = 5\n",
        "\n",
        "# Keeping the network in train mode\n",
        "model_vgg16.train()\n",
        "train_losses,  train_accuracy = [], []\n",
        "\n",
        "# Loop for no of epochs\n",
        "for e in range(epoch):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    # Iterate through all the batches in each epoch\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "      # Convert the image and label to gpu for faster execution\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Passing the data to the model (Forward Pass)\n",
        "      outputs = model_vgg16(images)\n",
        "\n",
        "      # Calculating the loss\n",
        "      loss = criterion(outputs, labels)\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      # Zero the parameter gradients\n",
        "      optimizer1.zero_grad()\n",
        "\n",
        "      # Performing backward pass (Backpropagation)\n",
        "      loss.backward()\n",
        "\n",
        "      # optimizer1.step() updates the weights accordingly\n",
        "      optimizer1.step()\n",
        "\n",
        "      # Accuracy calculation\n",
        "      _, predicted = torch.max(outputs, 1) #_, => stores all the index of the maximum output\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_losses.append(train_loss/len(trainset))\n",
        "    train_accuracy.append(100 * correct/len(trainset))\n",
        "    print('epoch: {}, Train Loss:{:.6f} Train Accuracy: {:.2f} '.format(e+1,train_losses[-1], train_accuracy[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dneQFl-1DS75"
      },
      "source": [
        "### Test the Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nemM4ldaDS76"
      },
      "outputs": [],
      "source": [
        "model_vgg16.eval()\n",
        "\n",
        "image = current_Images[10]\n",
        "\n",
        "# Add an extra batch dimension since pytorch treats all images as batches\n",
        "output = model_vgg16(image.unsqueeze(0).to(device))\n",
        "\n",
        "_, predicted = torch.max(output, 1)\n",
        "\n",
        "trainset.classes[predicted.item()], predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIZSrI_tDS76"
      },
      "outputs": [],
      "source": [
        "# Keeping the network in evaluation mode\n",
        "model_vgg16.eval()\n",
        "\n",
        "Test_accuracy = 0\n",
        "predictions, test_images1 = [], []\n",
        "# Iterate through all the batches in each epoch\n",
        "for images,labels in test_loader:\n",
        "    # Convert the images and labels to gpu for faster execution\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Do the forward pass\n",
        "    outputs = model_vgg16(images)\n",
        "\n",
        "    # Accuracy calculation\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    Test_accuracy += (predicted == labels).sum().item()\n",
        "    test_images1.extend(images.cpu())\n",
        "    predictions.extend(predicted.cpu())\n",
        "\n",
        "Accuracy = Test_accuracy / len(testset)\n",
        "print(\"Accuracy of Test Data is\", Accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnAStrI7DS77"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 4, figsize = (6,6))\n",
        "axes = axes.reshape(-1)\n",
        "import numpy as np\n",
        "for i in np.arange(0, len(test_images1)):\n",
        "    axes[i].imshow(test_images1[i].permute(1, 2, 0))\n",
        "    axes[i].set_title(predictions[i])\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r35isHfTVGKc"
      },
      "source": [
        "#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Walkthrough = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to submit your notebook for Ungrading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}