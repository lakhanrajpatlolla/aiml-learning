{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakhanrajpatlolla/aiml-learning/blob/master/U4W18_59_Tuning_Hyper_Parameter_Learning_Rate_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlDT2pxVVYIH"
      },
      "source": [
        "## Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyCF3t5T6k5g"
      },
      "source": [
        "## Learning Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UIQ42UP6nay"
      },
      "source": [
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "1. Understand the role of hyperparameter learning rate\n",
        "2. Observe what happens to the performance of the model when we set learning rate values to high or low"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otjY3N71Psfx"
      },
      "source": [
        "## Experiment walkthrough video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLYMN84lyNR9"
      },
      "source": [
        "Please refer video explanation of U4W18_64_Weight_InitializationandUpdates for this. This experiment is an extension of the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mO2VQ0A6oO-"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_m0jyuG6p6K"
      },
      "source": [
        "### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydFMJSX16uKU"
      },
      "source": [
        "The dataset used for this experiment is CIFAR-100. It  has 100 classes which contains 600 images for each class. There are 500 training images and 100 testing images per class. These 100 classes are grouped into 20 superclasses. Each image comes with the class and superclass it belongs to.\n",
        "\n",
        "Here is the list of classes in the CIFAR-100:\n",
        "\n",
        "| Superclass \t | Classes|\n",
        "|--------------------|-------------|\n",
        "|aquatic mammals | \tbeaver, dolphin, otter, seal, whale |\n",
        "|fish |\taquarium fish, flatfish, ray, shark, trout |\n",
        "|flowers| \torchids, poppies, roses, sunflowers, tulips |\n",
        "|food containers| \tbottles, bowls, cans, cups, plates|\n",
        "|fruit and vegetables| \tapples, mushrooms, oranges, pears, sweet peppers|\n",
        "|household electrical devices | clock, computer keyboard, lamp, telephone, television|\n",
        "|household furniture| \tbed, chair, couch, table, wardrobe|\n",
        "|insects | \tbee, beetle, butterfly, caterpillar, cockroach |\n",
        "|large carnivores| \tbear, leopard, lion, tiger, wolf|\n",
        "|large man-made outdoor things |\tbridge, castle, house, road, skyscraper|\n",
        "|large natural outdoor scenes |\tcloud, forest, mountain, plain, sea|\n",
        "|large omnivores and herbivores |\tcamel, cattle, chimpanzee, elephant, kangaroo|\n",
        "|medium-sized mammals |\tfox, porcupine, possum, raccoon, skunk|\n",
        "|non-insect invertebrates|\tcrab, lobster, snail, spider, worm|\n",
        "|people| \tbaby, boy, girl, man, woman|\n",
        "|reptiles |\tcrocodile, dinosaur, lizard, snake, turtle|\n",
        "|small mammals| \thamster, mouse, rabbit, shrew, squirrel |\n",
        "|trees|\tmaple, oak, palm, pine, willow |\n",
        "|vehicles 1 |\tbicycle, bus, motorcycle, pickup truck, train |\n",
        "|vehicles 2 |\tlawn-mower, rocket, streetcar, tank, tractor |\n",
        "\n",
        "\n",
        "\n",
        "The dataset is downloaded from following url :\n",
        "\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUBMuYhs6xaN"
      },
      "source": [
        "## AI / ML Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkHCjIwK60x9"
      },
      "source": [
        "### Learning Rate\n",
        "\n",
        "\n",
        "\n",
        "This is the most important hyper parameter to train the neural network. A good learning rate can make a huge difference in between a model that didn't learn anything and a model that learned everything from the data.\n",
        "\n",
        "Let us see some intersting facts about the learning rates :\n",
        "\n",
        "1. While training the model when we observe that the loss is exploding we infer that the value chosen for learning rate is high.\n",
        "2. If you choose learning rate value as too high then there is a chance to overshoot the local minima or good result and in next iteration there is a chance to undershoot the good result.\n",
        "3.  If you choose learning rate value as too low then there is a slow convergence. This can even degrade the performance of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sFKC2BJ63s1"
      },
      "source": [
        "In this experiment you will be able to understand how the performance of the model varies when we change the learning rate value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2418775\" #@param {type:\"string\"}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEzlYL4CDrmE"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"9959000490\" #@param {type:\"string\"}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form",
        "outputId": "45bf2bd4-b209-40f3-d00f-1cdaff3aa289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import re\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"U4W18_59_Tuning_Hyper_Parameter_Learning_Rate_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    from IPython.display import HTML, display\n",
        "    ipython.magic(\"sx pip3 install torch\")\n",
        "    ipython.magic(\"sx pip3 install torchvision\")\n",
        "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week9/Exp6/config.py\")\n",
        "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week9/Exp6/utils.py\")\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_inclass_mentor\": Mentor_support}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://learn-iiith.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getWalkthrough():\n",
        "  try:\n",
        "    if not Walkthrough:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Walkthrough\n",
        "  except NameError:\n",
        "    print (\"Please answer Walkthrough Question\")\n",
        "    return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2418775&recordId=2200\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTA5H991VYIM"
      },
      "source": [
        "### Importing required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqStPzYMVYIN"
      },
      "source": [
        "# Importing pytorch packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Importing config.py file\n",
        "import config as cf\n",
        "from utils import *\n",
        "\n",
        "# Importing python packages\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1fOb-Y_VYIS"
      },
      "source": [
        "# Checking for GPU instance\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Intilizaing the accuracy value as zero\n",
        "best_acc = 0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipFKYYbgVYIW"
      },
      "source": [
        "### Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhn7U19KVYIX",
        "outputId": "e346f4aa-ace0-4508-a473-e4a545f33d5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('\\n[Phase 1] : Data Preparation')\n",
        "\n",
        "# Dataset\n",
        "dataset = 'cifar100'\n",
        "\n",
        "# Preparing the dataset\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cf.mean[dataset], cf.std[dataset]),\n",
        "]) # mean and std transformation\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cf.mean[dataset], cf.std[dataset]),\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Phase 1] : Data Preparation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qDpWSEHVYIj"
      },
      "source": [
        "### Downloading and Loading the dataset\n",
        "\n",
        "The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNGgWJHGVYIk"
      },
      "source": [
        "# Number of classes in the dataset\n",
        "num_classes = 100"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz_YvckQVYIo",
        "outputId": "0a8abf6c-d4ad-477e-ad3a-d3cd5ec8193e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Downloading the dataset\n",
        "trainset = torchvision.datasets.CIFAR100(root='data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR100(root='data', train=False, download=False, transform=transform_test)\n",
        "\n",
        "# Loading the dataset\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=8)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:13<00:00, 12.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5PZj1gdVYIv"
      },
      "source": [
        "### Let us define the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTbr0F0aVYIw"
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes, init_mode='xavier'):  # Supports 'zero', 'normal', 'xavier', 'he' initialization\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1   = nn.Linear(16*5*5, 120)\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, num_classes)\n",
        "\n",
        "        if init_mode == 'zero':\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                    m.weight.data.zero_()   # Fill tensor elements with zeros\n",
        "                    if m.bias is not None:\n",
        "                        m.bias.data.zero_()\n",
        "\n",
        "        if init_mode == 'normal':\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                    m.weight.data.normal_()   # Fill tensor elements with random numbers from normal distribution\n",
        "                    if m.bias is not None:\n",
        "                        m.bias.data.normal_()\n",
        "\n",
        "        if init_mode == 'xavier':\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d):\n",
        "                    fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                    fan_in = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n",
        "                    n = fan_in + fan_out\n",
        "                    m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                    if m.bias is not None:\n",
        "                        m.bias.data.normal_(0, math.sqrt(2. / n))\n",
        "                if isinstance(m, nn.Linear):\n",
        "                    size = m.weight.size()\n",
        "                    fan_out = size[0] # Number of rows\n",
        "                    fan_in = size[1] # Number of columns\n",
        "                    variance = math.sqrt(2.0/(fan_in+fan_out))\n",
        "                    m.weight.data.normal_(0.0, variance)\n",
        "                    if m.bias is not None:\n",
        "                        m.bias.data.normal_(0, variance)\n",
        "\n",
        "        if init_mode == 'he':\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d):\n",
        "                    n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                    m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                    if m.bias is not None:\n",
        "                        m.bias.data.normal_(0, math.sqrt(2. / n))\n",
        "                if isinstance(m, nn.Linear):\n",
        "                    size = m.weight.size()\n",
        "                    fan_out = size[0] # Number of rows\n",
        "                    fan_in = size[1] # Number of columns\n",
        "                    variance = math.sqrt(2.0/(fan_in))\n",
        "                    m.weight.data.normal_(0.0, variance)\n",
        "                    if m.bias is not None:\n",
        "                        m.bias.data.normal_(0, variance)\n",
        "\n",
        "\n",
        "    # Forward Pass\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return(out)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaBFZzZiVYI0"
      },
      "source": [
        "### Training with Xavier init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hn2v9-TVYI2"
      },
      "source": [
        "# Calling the model with Xavier\n",
        "net = LeNet(num_classes, init_mode='xavier')\n",
        "\n",
        "# Checking for GPU instance\n",
        "net = net.to(device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOR-ZShc2sK4"
      },
      "source": [
        "### Defining the Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK-JIPDxVYI5"
      },
      "source": [
        "# Intiliazing the loss\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVBUKGoK3Jqo"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRbViJdKVYI-"
      },
      "source": [
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Looping over train data\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "\n",
        "        # Converting targets and inputs into pytorch variables\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Set the parameters of gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward Pass\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        # Storing the outputs size\n",
        "        size_ = outputs.size()\n",
        "\n",
        "        # Reducing the dimenssion\n",
        "        outputs_ = outputs.view(size_[0], num_classes)\n",
        "\n",
        "        # Calculating the loss\n",
        "        loss = criterion(outputs_, targets)\n",
        "\n",
        "        # Backward Pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimizer Step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculating the training loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Predicting the values\n",
        "        _, predicted = torch.max(outputs_.data, 1)\n",
        "\n",
        "        # Storing the targets size\n",
        "        total += targets.size(0)\n",
        "\n",
        "        # Calculating the corrected values\n",
        "        correct += predicted.eq(targets.data).cpu().sum().item()\n",
        "\n",
        "        # Printing the data\n",
        "        if batch_idx%30 == 0 or batch_idx == len(trainloader)-1:\n",
        "            # Printing the progress bar\n",
        "            progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                         % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    # Storing number of epoch,loss and accuracy in a file\n",
        "    train_loss_file.write('%d %.3f %.3f\\n' %(epoch, train_loss/len(trainloader), 100.*correct/total))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMEncVnu3M8T"
      },
      "source": [
        "### Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5rNwNEyVYJC"
      },
      "source": [
        "def test(epoch):\n",
        "    global best_acc\n",
        "\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Looping over test data\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "\n",
        "        # Converting inputs and targets into pytorch variables\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Forward Pass\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        # Storing the outputs size\n",
        "        size_ = outputs.size()\n",
        "\n",
        "        # Reducing the dimenssions\n",
        "        outputs_ = outputs.view(size_[0], num_classes)\n",
        "\n",
        "        # Calculating the loss\n",
        "        loss = criterion(outputs_, targets)\n",
        "\n",
        "        # Calculating the test loss\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Storing the predicted values\n",
        "        _, predicted = torch.max(outputs_.data, 1)\n",
        "\n",
        "        # Storing the targets size\n",
        "        total += targets.size(0)\n",
        "\n",
        "        # Caluculating the correct values\n",
        "        correct += predicted.eq(targets.data).cpu().sum().item()\n",
        "\n",
        "        # Printing the data\n",
        "        if batch_idx%30 == 0 or batch_idx == len(testloader)-1:\n",
        "            # Printing the progress bar\n",
        "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    # Printing the validation loss\n",
        "    print('val_loss: ',  test_loss/len(testloader), 'accuracy: ', 100.0*correct/total)\n",
        "    # Storing number of epoch,loss and accuracy in a file\n",
        "    val_loss_file.write('%d %.3f %.3f\\n' %(epoch,  test_loss/len(testloader), 100.*correct/total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    # Checking for best accuracy\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net,\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        # Checking whether its a directory or not\n",
        "        if not os.path.isdir('../checkpoint'):\n",
        "            # Creating a directory\n",
        "            os.mkdir('../checkpoint')\n",
        "        # Saving the data\n",
        "        torch.save(state, '../checkpoint_ckpt.t7')\n",
        "        # Storing the best accuracy\n",
        "        best_acc = acc"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9NmsNhxVYJG"
      },
      "source": [
        "experiment = 'lr_schedule'\n",
        "\n",
        "# Creating files in write mode\n",
        "train_loss_file = open(experiment+\"train_loss.txt\", \"w\")\n",
        "val_loss_file = open(experiment+\"val_loss.txt\", \"w\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w8aNM95VYJL",
        "outputId": "b0777109-6785-4f24-9c93-640e7364cbb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# This code cell takes 20 mins to run\n",
        "\n",
        "# Training and testing the model for 60 epochs\n",
        "for epoch in range(0, 10):\n",
        "    if epoch == 50:\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
        "    if epoch == 30:\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "    if epoch == 0:\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "    # Training the model\n",
        "    train(epoch)\n",
        "    # Testing the model\n",
        "    test(epoch)\n",
        "\n",
        "# Closing the files\n",
        "train_loss_file.close()\n",
        "val_loss_file.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [==================================>] | Loss: 4.212 | Acc: 6.426% (3213/50000) \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 391/391 \n",
            " [==================================>] | Loss: 3.851 | Acc: 11.440% (1144/10000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 100/100 \n",
            "val_loss:  3.850965483188629 accuracy:  11.44\n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [==================================>] | Loss: 3.649 | Acc: 14.614% (7307/50000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 391/391 \n",
            " [==================================>] | Loss: 3.563 | Acc: 16.080% (1608/10000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 100/100 \n",
            "val_loss:  3.5627967381477355 accuracy:  16.08\n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [==================================>] | Loss: 3.398 | Acc: 18.696% (9348/50000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 391/391 \n",
            " [==================================>] | Loss: 3.344 | Acc: 18.930% (1893/10000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 100/100 \n",
            "val_loss:  3.344171259403229 accuracy:  18.93\n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [==================================>] | Loss: 3.230 | Acc: 21.494% (10747/50000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 391/391 \n",
            " [==================================>] | Loss: 3.202 | Acc: 22.230% (2223/10000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 100/100 \n",
            "val_loss:  3.201642916202545 accuracy:  22.23\n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            " [==================================>] | Loss: 3.112 | Acc: 23.924% (11962/50000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 391/391 \n",
            " [==================================>] | Loss: 3.185 | Acc: 21.990% (2199/10000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 100/100 \n",
            "val_loss:  3.18453905582428 accuracy:  21.99\n",
            "\n",
            "Epoch: 5\n",
            " [==================================>] | Loss: 3.018 | Acc: 25.418% (12709/50000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 391/391 \n",
            " [==================================>] | Loss: 3.024 | Acc: 25.530% (2553/10000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 100/100 \n",
            "val_loss:  3.023847506046295 accuracy:  25.53\n",
            "Saving..\n",
            "\n",
            "Epoch: 6\n",
            " [==================================>] | Loss: 2.947 | Acc: 27.160% (13580/50000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 391/391 \n",
            " [==================================>] | Loss: 3.041 | Acc: 25.270% (2527/10000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 100/100 \n",
            "val_loss:  3.040798442363739 accuracy:  25.27\n",
            "\n",
            "Epoch: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDMll3RCVYJR"
      },
      "source": [
        "### Plotting the training curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRLIKRPpVYJT"
      },
      "source": [
        "training_curves(experiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-b-CEcpkOCi"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12SwfIaukOCj"
      },
      "source": [
        "#@title State True or False: In the experiemnt above, as epochs increase, the learning rate value is increased ? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"FALSE\" #@param [\"\",\"TRUE\", \"FALSE\"]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0DzTLAMkOCj"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good and Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlMms_IykOCj"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"Good\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHnMPzf_kOCk"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRKla4emkOCk"
      },
      "source": [
        "#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Walkthrough = \"Somewhat Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtkER1AwkOCk"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Somewhat Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-UhjrabkOCk"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "MUHD7LC0kOCk"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}