{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakhanrajpatlolla/aiml-learning/blob/master/U2W9_31_Polynomial_Fitting_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zSWyuZTlYS1"
      },
      "source": [
        "\n",
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU2MBx7JtTyP"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot3pfe3AtWaN"
      },
      "source": [
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "\n",
        "* understand Bias and Variance    \n",
        "* know how does the degree of the polynomial affect the bias and variance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiV7Z4S-52SJ",
        "cellView": "form"
      },
      "source": [
        "#@title Experiment Explanation Video\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<video width=\"854\" height=\"480\" controls>\n",
        "  <source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/module_2_week_8_experment_3.mp4\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35RBpSDUtYUm"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVIILnxWtcKA"
      },
      "source": [
        "### Description\n",
        "\n",
        "In this experiment we have chosen sine curve a real data.  As the real-world is never perfectly clean however, we add noise to the curve to show that the real world data is noisy. This is done by adding a small random number to each value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi4X52VouBL4"
      },
      "source": [
        "## AI /ML Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgAparrouDiQ"
      },
      "source": [
        "In this experiment, we use the sine curve to understand how the change in bias and variance effects the degree of polynomial.\n",
        "\n",
        "\n",
        "### Bias and Variance:\n",
        "\n",
        "The **bias** is an error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).\n",
        "\n",
        "The **variance** is an error from sensitivity to small fluctuations in the training set. High variance can cause an algorithm to model the random noise in the training data, rather than the intended outputs (overfitting). The below image shows how the overfitting and underfitting looks.\n",
        "\n",
        "![alt text](https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/Overfitting.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "You can use any polynomial of higher order to project the idea of bias and variance. However, the sine values suits our experiment better because, it is a curve which is complex enough not to fit with simple linear or quadratic equations (to show bias) however it will overfit our data with higher order polynomials (6th order).\n",
        "\n",
        "We want to try and capture the data using a polynomial function. A polynomial is defined by the degree, or the highest power for the x-values. A line has a degree of 1 because it is of the form $y = m_1*x + c$ where $m$ is the slope and $c$ is the intercept. A third degree polynomial would have the form $y = m_3 * x^3 + m_2 * x^2 + m_1* x + c$ and so on. The higher the degree of the polynomial, the more flexible the model.\n",
        "\n",
        "\n",
        "We use fit_poly() to create a polynomial function with the specified number of degrees and plots the results. We can use these results to determine the optimal degrees to achieve the right balance between overfitting and underfitting.\n",
        "\n",
        "\n",
        "In this experiment, we will try :\n",
        "* To observe how the model changes with changing degrees.\n",
        "* To estimate the errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEzlYL4CDrmE"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import re\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"U2W9_31_Polynomial_Fitting_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    from IPython.display import HTML, display\n",
        "    ipython.magic(\"sx wget -qq https://cdn.talentsprint.com/aiml/Experiment_related_data/week1/Exp1/AIML_DS_REGR01_SIMPLEPENDULUMOSCILLATIONDATA.txt\")\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_inclass_mentor\": Mentor_support}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://learn-iiith.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getWalkthrough():\n",
        "  try:\n",
        "    if not Walkthrough:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Walkthrough\n",
        "  except NameError:\n",
        "    print (\"Please answer Walkthrough Question\")\n",
        "    return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEeo3n0ElYS_"
      },
      "source": [
        "## Importing the required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFmT3W9flYTD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Scikit-Learn packages for fitting models\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-Ds7YIulYTI"
      },
      "source": [
        "## Generating the Data\n",
        "\n",
        "We define a curve, in this case a sine curve to serve as our process that generates the data. As the real-world is never perfectly clean however, we also need to add some noise into the observations. This is done by adding a small random number to each value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs-y6GqqlYTK"
      },
      "source": [
        "# Set the random seed for reproducible results\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generating function representing a process in real life\n",
        "def true_gen(x):\n",
        "    y = np.sin(1.2 * x * np.pi)\n",
        "    return(y)\n",
        "\n",
        "# x values and y value with a small amount of random noise\n",
        "x = np.sort(np.random.rand(120))\n",
        "y = true_gen(x) + 0.1 * np.random.randn(len(x)) # Basically for each value of pure sin(x), we are adding a small random value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwMjhoOflYTO"
      },
      "source": [
        "## Training and Testing\n",
        "\n",
        "The np.random.choice() method returns a randomly selected element from the specified sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_HykToalYTQ"
      },
      "source": [
        "# Random indices for creating training and testing sets\n",
        "random_ind = np.random.choice(list(range(120)), size = 120, replace=False)\n",
        "x_t = x[random_ind] # For the elements in the array x, random elements are chosen based on the index deterimined by random_ind\n",
        "y_t = y[random_ind]\n",
        "\n",
        "# Training and testing observations\n",
        "train = x_t[:int(0.7 * len(x))] # We are now choosing 70% of data as training and the remaining below as test.\n",
        "test = x_t[int(0.7 * len(x)):]\n",
        "\n",
        "y_train = y_t[:int(0.7 * len(y))]\n",
        "y_test = y_t[int(0.7 * len(y)):]\n",
        "\n",
        "# Model the true curve. As you might have noticed, here too we are calling the true_gen method. But here the difference is..\n",
        "# ...the input is a continuous values of x (determined by np.linspace, which gives uniformly spaced values) for that we are getting\n",
        "# ..the sin(x) value, and thus fit_poly(train, y_train, test, y_test, degrees = 1, plot='test') this time plotting the sine curve itself (above we just created 'points' following sine curve)\n",
        "x_linspace = np.linspace(0, 1, 1000)\n",
        "y_true = true_gen(x_linspace)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2uwd-sDa0Dl"
      },
      "source": [
        "x_t.shape, y_t.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze9xVifrlYTT"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkvhKsRwlYTV"
      },
      "source": [
        "# Visualize observations and true curve\n",
        "plt.plot(train, y_train, 'ko', label = 'Train')\n",
        "plt.plot(test, y_test, 'ro', label = 'Test')\n",
        "plt.plot(x_linspace, y_true, 'b-', linewidth = 2, label = 'True function')\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRxbemV4lYTd"
      },
      "source": [
        "## Polynomial Model\n",
        "\n",
        "We want to try and capture the data using a polynomial function. A polynomial is defined by the degree, or the highest power for the x-values. A line has a degree of 1 because it is of the form $y = m_1*x + c$ where $m$ is the slope and $c$ is the intercept. A third degree polynomial would have the form $y = m_3 * x^3 + m_2 * x^2 + m_1* x + c$ and so on. The higher the degree of the polynomial, the more flexible the model.\n",
        "\n",
        "The following function creates a polynomial with the specified number of degrees and plots the results. We can use these results to determine the optimal degrees to achieve the right balance between overfitting and underfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNMZTgcwlYTe"
      },
      "source": [
        "def fit_poly(train, y_train, test, y_test, degrees, plot='train', return_scores=False):\n",
        "\n",
        "    # Creates a polynomial transformation model for the given degree. For example for degree 2, (x**0, x**1, x**2) i.e. if x=2 then 2**0, 2**1,2**2 => (1,2,4)\n",
        "    # So a point in 1-D is converted to a point in 2-D, and so on for even higher degree.\n",
        "    features = PolynomialFeatures(degree=degrees, include_bias=False)\n",
        "\n",
        "    # Reshape train features\n",
        "    train = train.reshape(-1, 1)\n",
        "\n",
        "    # Transforming the train features to higher order\n",
        "    train_trans = features.fit_transform(train)\n",
        "\n",
        "    # Create the Linear Regression model\n",
        "    # Fit the transformed features to Linear Regression\n",
        "    model = LinearRegression()\n",
        "    model.fit(train_trans, y_train)\n",
        "\n",
        "    # Predicting on train data\n",
        "    train_predictions = model.predict(train_trans)\n",
        "\n",
        "    # Evaluating the model on training dataset\n",
        "    training_error = mean_squared_error(y_train, train_predictions)\n",
        "\n",
        "    # Reshape test features and transform the features to higher order\n",
        "    test = test.reshape(-1, 1)\n",
        "    test_trans = features.fit_transform(test)\n",
        "\n",
        "    # Predicting on test data\n",
        "    test_predictions = model.predict(test_trans)\n",
        "\n",
        "    # Evaluating the model on testing dataset\n",
        "    testing_error = mean_squared_error(y_test, test_predictions)\n",
        "\n",
        "    # Find the model curve and the true curve\n",
        "    x_curve = np.linspace(0, 1, 100)\n",
        "    x_curve = x_curve.reshape(-1, 1)\n",
        "    x_curve_trans = features.fit_transform(x_curve)\n",
        "\n",
        "    # Model curve\n",
        "    model_curve = model.predict(x_curve_trans)\n",
        "\n",
        "    # True curve\n",
        "    y_true_curve = true_gen(x_curve[:, 0])\n",
        "\n",
        "    # Plot observations, true function, and model predicted function\n",
        "    if plot == 'train':\n",
        "        plt.plot(train[:, 0], y_train, 'ko', label = 'Observations')\n",
        "        plt.plot(x_curve[:, 0], y_true_curve, linewidth = 4, label = 'True Function')\n",
        "        plt.plot(x_curve[:, 0], model_curve, linewidth = 4, label = 'Model Function')\n",
        "        plt.xlabel('x'); plt.ylabel('y')\n",
        "        plt.legend()\n",
        "        plt.ylim(-1, 1.5); plt.xlim(0, 1)\n",
        "        plt.title('{} Degree Model on Training Data'.format(degrees))\n",
        "        plt.show()\n",
        "\n",
        "    elif plot == 'test':\n",
        "        # Plot the test observations and test predictions\n",
        "        plt.plot(test, y_test, 'o', label = 'Test Observations')\n",
        "        plt.plot(x_curve[:, 0], y_true_curve, 'b-', linewidth = 2, label = 'True Function')\n",
        "        plt.plot(test, test_predictions, 'ro', label = 'Test Predictions')\n",
        "        plt.ylim(-1, 1.5); plt.xlim(0, 1)\n",
        "        plt.legend(), plt.xlabel('x'), plt.ylabel('y')\n",
        "        plt.title('{} Degree Model on Testing Data'.format(degrees)), plt.show()\n",
        "\n",
        "     # Return the metrics\n",
        "    if return_scores:\n",
        "        return training_error, testing_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAD-3BK3lYTj"
      },
      "source": [
        "## Fitting Model with Different Degrees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7j_cmzwlYTk"
      },
      "source": [
        "**Degrees = 1 -> Underfitting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2UE_bJ4lYTl"
      },
      "source": [
        "For example, a degree-1 polynomial fits a straight line to the data. In this case a linear model cannot accurately learn the relationship between x and y so it will underfit the data. This is because an underfit model has low variance and high bias. Variance refers to how much the model is dependent on the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rbtAKQxlYTn"
      },
      "source": [
        "fit_poly(train, y_train, test, y_test, degrees = 1, plot='train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzWS00w7lYTt"
      },
      "source": [
        " The model predictions for the testing data are shown compared to the true function and testing data points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3vLgyIRlYTu"
      },
      "source": [
        "fit_poly(train, y_train, test, y_test, degrees = 1, plot='test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTuUY31BlYT0"
      },
      "source": [
        "**Degrees = 25 -> Overfitting**\n",
        " An overfit model will have extremely low training error but a high testing error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxXVQ4cYlYT0"
      },
      "source": [
        "We can go in the completely opposite direction and create a model that overfits the data. This model has too much flexibility and learns the training data too closely. As the training data has some amount of noise, it will end up capturing that noise and will be misled by that noise when it tries to make predictions on the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ifkNSyElYT2"
      },
      "source": [
        "This is a model with a high variance, because it will change significantly depending on the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkf8acYGlYT3"
      },
      "source": [
        "fit_poly(train, y_train, test, y_test, degrees = 25, plot='train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPzcYPVAlYT9"
      },
      "source": [
        "fit_poly(train, y_train, test, y_test, degrees = 25, plot='test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2PLTUUqlYUD"
      },
      "source": [
        "**Degrees = 5 -> Balanced Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQiE2qlVlYUF"
      },
      "source": [
        "Now that we have seen the two extremes, we can take a look at a model that does a good job of both accounting for the data while not following it too closely.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTiXSqgylYUH"
      },
      "source": [
        "fit_poly(train, y_train, test, y_test, degrees = 5, plot='train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPYn-VaZlYUN"
      },
      "source": [
        "fit_poly(train, y_train, test, y_test, degrees = 5, plot='test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGUWiN9ulYUW"
      },
      "source": [
        "# Range of model degrees to evaluate\n",
        "degrees = [int(x) for x in np.linspace(1, 40, 40)]\n",
        "\n",
        "# Store the results of a dataframe\n",
        "results = pd.DataFrame(0, columns = ['train_error', 'test_error'], index = degrees)\n",
        "\n",
        "# Try each value of degrees for the model and record the results\n",
        "for degree in degrees:\n",
        "    degree_results = fit_poly(train, y_train, test, y_test, degree, plot=False, return_scores=True)\n",
        "    results.loc[degree, 'train_error'] = degree_results[0]\n",
        "    results.loc[degree, 'test_error'] = degree_results[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foOW6XK1lYUg"
      },
      "source": [
        "## Evaluate Models\n",
        "\n",
        "We will use a range of values to see how the performance on the training and testing set compares. A model with much lower errors on the training data than the testing data is overfit. A model with high error on the training data (which will lead to high testing error as well) is underfitting because it does not even learn the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n4RwWmIlYUh"
      },
      "source": [
        "print('Training Errors\\n')\n",
        "train_eval = results.sort_values('train_error').reset_index(level=0).rename(columns={'index': 'degrees'})\n",
        "train_eval.loc[:,['degrees', 'train_error']].head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLsJ72v3lYUq"
      },
      "source": [
        "print('Testing Errors\\n')\n",
        "test_eval = results.sort_values('test_error').reset_index(level=0).rename(columns={'index': 'degrees'})\n",
        "test_eval.loc[:,['degrees', 'test_error']] .head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8MLzLvFEo3y"
      },
      "source": [
        "## Plotting Training and Testing Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UF64f7tlYUx"
      },
      "source": [
        "# Plotting both the train and test against the model complexity\n",
        "plt.plot(results.index, results['train_error'], 'b', label = 'Training Error')\n",
        "plt.plot(results.index, results['test_error'], 'r',  label = 'Testing Error')\n",
        "plt.legend(loc=2)\n",
        "plt.xlabel('Degrees')\n",
        "plt.ylabel('Mean Square Error')\n",
        "plt.title('Training and Testing Curves');\n",
        "plt.ylim(0, 0.05)\n",
        "plt.show()\n",
        "\n",
        "print('\\nMinimum Training Error occurs at {} degrees.'.format((results['train_error'].idxmin())))\n",
        "print('Minimum Testing Error occurs at {} degrees.\\n'.format((results['test_error'].idxmin())))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4-oWiOAI7kZ"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvm-8H2RI7kd"
      },
      "source": [
        "#@title For a 1-D point x=3, does the higher order feature of degree 3 result (2,4,8)? (Refer SkLearn's \"PolynomialFeatures\" method to answer this) { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\",\"TRUE\", \"FALSE\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94dIhQKDI7kf"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKzGvfdyI7kg"
      },
      "source": [
        "#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Walkthrough = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OjkIq7II7kh"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwLT_C0vI7ki"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "gPMKJg_eI7kj"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}