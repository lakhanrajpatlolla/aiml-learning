{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakhanrajpatlolla/aiml-learning/blob/master/TalentSprint_IIIT_Colab_Tensor_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq3WVvu7skLd"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint\n",
        "\n",
        "## Tensor basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjWHjEgRAuVL"
      },
      "source": [
        "### Setup Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "R10gTaB_a4RI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d68501-8ad2-4dd7-8a04-7991ef4f5535"
      },
      "source": [
        "!pip3 install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yQyeW447oPX"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0m8NquV9AkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf295c2-3f9d-4865-aa1e-cb2ce1963d5d"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3Gvc41f_sZX"
      },
      "source": [
        "#**Tensor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibPI9LWv3n1I"
      },
      "source": [
        "###Initializing a tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boujstAO_tez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e74f692-c199-4235-d18a-d2ab1d24b193"
      },
      "source": [
        "# Initializing a tensor\n",
        "a = torch.Tensor([2,3])\n",
        "print(a.size())\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2])\n",
            "tensor([2., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvRbCmeeA8-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92c56264-4952-4d3a-a028-7b8305737833"
      },
      "source": [
        "a.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaOUoWCIgzkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5991faa5-df3c-41d1-8d30-75eabc295946"
      },
      "source": [
        "t = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(t)\n",
        "print(t.size())\n",
        "print(t.t())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.Size([2, 3])\n",
            "tensor([[1., 4.],\n",
            "        [2., 5.],\n",
            "        [3., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erGJUPD_3wnf"
      },
      "source": [
        "### Creating a scalar tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntQetme0JVrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "660388b3-8fe1-4ad6-9229-1da8b5adb533"
      },
      "source": [
        "a = torch.tensor(200)\n",
        "print(a)\n",
        "print(a.size())\n",
        "print(a.type())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(200)\n",
            "torch.Size([])\n",
            "torch.LongTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVe0vlBf33Rk"
      },
      "source": [
        "###Converting scalar to python number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG-0BGYS31NC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc35967-ffa1-4548-b1a7-4fa6d40415df"
      },
      "source": [
        "print(a.item())\n",
        "print(type(a.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "<class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkaFxLkq4BU1"
      },
      "source": [
        "###Creating a float tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weOySs2yCdZr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1a00dfb-73a9-419d-e185-9758be1eb1be"
      },
      "source": [
        "a = torch.tensor([2.0,3])\n",
        "a.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4xjFsBB4E7V"
      },
      "source": [
        "###Providing the data type while creating the tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLNhdgLACwfN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f18412cf-f1f1-49b2-e356-87f027ad5709"
      },
      "source": [
        "a = torch.tensor([2,3],dtype=torch.int32)\n",
        "a.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.IntTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shuIdBhA4LAX"
      },
      "source": [
        "###Just like numpy, creating a tensor by copying another tensor results, pointing to same memory location\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtMzpVhkDhQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b90274-d565-45fa-cf2f-d750f86cb491"
      },
      "source": [
        "a = torch.tensor([2.0, 3])\n",
        "b = a\n",
        "c=a.clone()\n",
        "b[0] = 11\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([11.,  3.])\n",
            "tensor([11.,  3.])\n",
            "tensor([2., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymR9skNc4OfB"
      },
      "source": [
        "###2D tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ2VIKmgEW-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7512fc9f-b396-4af0-8d85-da4dca42b346"
      },
      "source": [
        "a = torch.tensor([[1,2],[3,4]])\n",
        "print(a)\n",
        "print(a.type())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "torch.LongTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.Tensor([[1,2],[3,4]])\n",
        "print(a)\n",
        "print(a.type())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KcxfviulwVO",
        "outputId": "3ae7d93f-14b2-4120-8da5-529d40194345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "torch.FloatTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeWWw8pd418E"
      },
      "source": [
        "###Creating and initializing a tensor with random values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-MUv5zpFRoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7470564b-6265-4065-83f6-f4160e484b60"
      },
      "source": [
        "a = torch.rand(3,4)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1276, 0.4317, 0.9916, 0.1817],\n",
            "        [0.6753, 0.3589, 0.6333, 0.1537],\n",
            "        [0.7595, 0.4174, 0.5072, 0.2446]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2fOgMay455N"
      },
      "source": [
        "###Creating and initializing a float tensor with zeros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9_68kZ8F7Ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc833840-0d9c-4601-9cdc-12ee006c95a3"
      },
      "source": [
        "a = torch.zeros((4,5), dtype=torch.float32)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vffsQ4344974"
      },
      "source": [
        "###Creating an Identity tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xBd2Fu1GqVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "272fd850-a12d-445e-dd8c-db7c25a38df8"
      },
      "source": [
        "a = torch.eye(4,4)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0.],\n",
            "        [0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ33siBjFGrN"
      },
      "source": [
        "#**Tensor Operations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4YECoP35BQm"
      },
      "source": [
        "###Addition of two tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahpXC1TQFJ5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ecf5886-9c72-419b-9d3d-1f123199e6be"
      },
      "source": [
        "x = torch.rand(3,3)\n",
        "y = torch.rand(3,3)\n",
        "z = x+y\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.5513, 0.6299, 0.9639],\n",
            "        [0.5222, 1.8294, 0.6160],\n",
            "        [1.4646, 1.5585, 0.7651]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncyqH1wm5G50"
      },
      "source": [
        "###Addition of two tensor (alternative)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgIqg4g4IfVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d13784f-9ba0-442d-ef81-01e65f787bf6"
      },
      "source": [
        "z = x.add(y)\n",
        "print(z)\n",
        "#z=x+y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.5513, 0.6299, 0.9639],\n",
            "        [0.5222, 1.8294, 0.6160],\n",
            "        [1.4646, 1.5585, 0.7651]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c=torch.tensor(20)\n",
        "print(c.size())\n",
        "c=torch.tensor([20])\n",
        "print(c.size())\n",
        "c=torch.tensor([[20]])\n",
        "print(c.size())\n",
        "c=torch.tensor([[[20]]])\n",
        "print(c.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqwYXyMsG7al",
        "outputId": "1a5666ca-5513-4be6-8646-da92a938e7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([])\n",
            "torch.Size([1])\n",
            "torch.Size([1, 1])\n",
            "torch.Size([1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIN8u1A_5OlI"
      },
      "source": [
        "###Inplace addition of two tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOqXYTkgIjfp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5e0a20-cfca-43d9-f1d2-406975f8ee41"
      },
      "source": [
        "print(x)\n",
        "\n",
        "x.add_(y)\n",
        "#x=x+y\n",
        "\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9090, 0.4799, 0.5538],\n",
            "        [0.3814, 0.9160, 0.2110],\n",
            "        [0.6788, 0.7827, 0.0369]])\n",
            "tensor([[1.5513, 0.6299, 0.9639],\n",
            "        [0.5222, 1.8294, 0.6160],\n",
            "        [1.4646, 1.5585, 0.7651]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI1TfG2B5lBP"
      },
      "source": [
        "###Element wise multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IxgHBbzIuDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e89af6-3246-4112-e12b-e8da8472c31a"
      },
      "source": [
        "print(x*y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9964, 0.0945, 0.3952],\n",
            "        [0.0735, 1.6709, 0.2494],\n",
            "        [1.1510, 1.2091, 0.5571]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naidinMb5oxT"
      },
      "source": [
        "###Matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtN0vws3KlbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d1183d3-ecd9-4151-9c16-03bdb63caa3a"
      },
      "source": [
        "z = torch.matmul(x,y[:,0])\n",
        "print(z)\n",
        "z.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.8425, 1.0770, 1.7614])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7qePwsG5zrc"
      },
      "source": [
        "###Reshaping tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKJcA3gxR1ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb7eff4-d888-40bf-c8a3-52ec0c8ef793"
      },
      "source": [
        "x = torch.rand(5,6)\n",
        "print(\"Size of x :\\n\",x.size())\n",
        "print(\"x:\\n\",x)\n",
        "y = x.view(30)\n",
        "print(\"Size of y :\\n\",y.size())\n",
        "print(\"y:\\n\",y)\n",
        "z = x.view(3,10)\n",
        "print(\"Size of z :\\n\",z.size())\n",
        "print(\"z:\\n\",z)\n",
        "z = x.view(-1,10)\n",
        "print(\"Size of z :\\n\",z.size())\n",
        "print(\"z:\\n\",z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of x :\n",
            " torch.Size([5, 6])\n",
            "x:\n",
            " tensor([[0.5752, 0.2789, 0.8191, 0.2044, 0.4438, 0.9614],\n",
            "        [0.1786, 0.5481, 0.5890, 0.6792, 0.8866, 0.0753],\n",
            "        [0.0729, 0.1541, 0.5422, 0.5503, 0.7769, 0.8733],\n",
            "        [0.4625, 0.3558, 0.2890, 0.7960, 0.9097, 0.4747],\n",
            "        [0.5152, 0.9119, 0.4208, 0.5016, 0.9535, 0.3619]])\n",
            "Size of y :\n",
            " torch.Size([30])\n",
            "y:\n",
            " tensor([0.5752, 0.2789, 0.8191, 0.2044, 0.4438, 0.9614, 0.1786, 0.5481, 0.5890,\n",
            "        0.6792, 0.8866, 0.0753, 0.0729, 0.1541, 0.5422, 0.5503, 0.7769, 0.8733,\n",
            "        0.4625, 0.3558, 0.2890, 0.7960, 0.9097, 0.4747, 0.5152, 0.9119, 0.4208,\n",
            "        0.5016, 0.9535, 0.3619])\n",
            "Size of z :\n",
            " torch.Size([3, 10])\n",
            "z:\n",
            " tensor([[0.5752, 0.2789, 0.8191, 0.2044, 0.4438, 0.9614, 0.1786, 0.5481, 0.5890,\n",
            "         0.6792],\n",
            "        [0.8866, 0.0753, 0.0729, 0.1541, 0.5422, 0.5503, 0.7769, 0.8733, 0.4625,\n",
            "         0.3558],\n",
            "        [0.2890, 0.7960, 0.9097, 0.4747, 0.5152, 0.9119, 0.4208, 0.5016, 0.9535,\n",
            "         0.3619]])\n",
            "Size of z :\n",
            " torch.Size([3, 10])\n",
            "z:\n",
            " tensor([[0.5752, 0.2789, 0.8191, 0.2044, 0.4438, 0.9614, 0.1786, 0.5481, 0.5890,\n",
            "         0.6792],\n",
            "        [0.8866, 0.0753, 0.0729, 0.1541, 0.5422, 0.5503, 0.7769, 0.8733, 0.4625,\n",
            "         0.3558],\n",
            "        [0.2890, 0.7960, 0.9097, 0.4747, 0.5152, 0.9119, 0.4208, 0.5016, 0.9535,\n",
            "         0.3619]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q8u8Ybl6aTE"
      },
      "source": [
        "###Generating Numbers in Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKZfbRSmTrKZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f878be7-776a-4683-e8ab-7954fe090cba"
      },
      "source": [
        "x = torch.arange(9)\n",
        "print(x)\n",
        "x = x.view(3,3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn3gIaFa6mgN"
      },
      "source": [
        "###Concatenating two tensors at a given dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq3lfDaV6ly8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfec7bc-fc2d-41ec-81ce-f53172d7c0a4"
      },
      "source": [
        "print(torch.cat((x,x),dim=0))\n",
        "print(torch.cat((x,x),dim=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8],\n",
            "        [0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "tensor([[0, 1, 2, 0, 1, 2],\n",
            "        [3, 4, 5, 3, 4, 5],\n",
            "        [6, 7, 8, 6, 7, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wztx_uOL6s4_"
      },
      "source": [
        "###Reducing the redundant dimension by squeeze operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bpPpJsVVPZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56043f82-1b7f-42d2-f813-0df50854ac75"
      },
      "source": [
        "x1= torch.rand(1,5)\n",
        "print(\"size of x1 squeezing:\\n\",x1.size())\n",
        "print(x1)\n",
        "x1 = x1.squeeze()\n",
        "print(\"size of x1 after squeezing:\\n\", x1.size())\n",
        "print(x1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of x1 squeezing:\n",
            " torch.Size([1, 5])\n",
            "tensor([[0.3536, 0.8186, 0.8420, 0.5294, 0.5314]])\n",
            "size of x1 after squeezing:\n",
            " torch.Size([5])\n",
            "tensor([0.3536, 0.8186, 0.8420, 0.5294, 0.5314])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUSXmKCTgzpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c9d95a-9802-4387-c8cc-d743098b9f24"
      },
      "source": [
        "x1 = torch.rand(1,1,5)\n",
        "print(\"size of x1 before squeezing:\\n\", x1.size())\n",
        "print(x1)\n",
        "x1 = x1.squeeze()\n",
        "print(\"size of x1 after squeezing:\\n\", x1.size())\n",
        "print(x1)\n",
        "print(x1.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of x1 before squeezing:\n",
            " torch.Size([1, 1, 5])\n",
            "tensor([[[0.1366, 0.3979, 0.4085, 0.4541, 0.9965]]])\n",
            "size of x1 after squeezing:\n",
            " torch.Size([5])\n",
            "tensor([0.1366, 0.3979, 0.4085, 0.4541, 0.9965])\n",
            "[0.13664645 0.39786088 0.40849692 0.4541359  0.9965352 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKD-tFDYe-lz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa2557b-fab0-43d4-d759-0d61dfcc191d"
      },
      "source": [
        "x2 = torch.rand(3,1,4,1,5)\n",
        "print(\"size of x2 before squeezing:\\n\", x2.size())\n",
        "print(x2)\n",
        "x2 = x2.squeeze()\n",
        "print(\"size of x2 after squeezing:\\n\", x2.size())\n",
        "print(x2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of x2 before squeezing:\n",
            " torch.Size([3, 1, 4, 1, 5])\n",
            "tensor([[[[[0.2371, 0.4476, 0.8551, 0.2201, 0.0108]],\n",
            "\n",
            "          [[0.9178, 0.9372, 0.4717, 0.2624, 0.5428]],\n",
            "\n",
            "          [[0.8091, 0.3367, 0.6744, 0.2808, 0.2231]],\n",
            "\n",
            "          [[0.8950, 0.9022, 0.0172, 0.0176, 0.3202]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[0.4712, 0.3305, 0.4078, 0.9796, 0.1717]],\n",
            "\n",
            "          [[0.6894, 0.8854, 0.8833, 0.8838, 0.9970]],\n",
            "\n",
            "          [[0.3611, 0.9187, 0.0893, 0.2255, 0.6699]],\n",
            "\n",
            "          [[0.6828, 0.6481, 0.4441, 0.6411, 0.0795]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[0.1536, 0.5694, 0.4721, 0.0741, 0.1530]],\n",
            "\n",
            "          [[0.3897, 0.9793, 0.9707, 0.7052, 0.8337]],\n",
            "\n",
            "          [[0.0832, 0.5157, 0.0460, 0.3986, 0.3475]],\n",
            "\n",
            "          [[0.9157, 0.0498, 0.8912, 0.9541, 0.0368]]]]])\n",
            "size of x2 after squeezing:\n",
            " torch.Size([3, 4, 5])\n",
            "tensor([[[0.2371, 0.4476, 0.8551, 0.2201, 0.0108],\n",
            "         [0.9178, 0.9372, 0.4717, 0.2624, 0.5428],\n",
            "         [0.8091, 0.3367, 0.6744, 0.2808, 0.2231],\n",
            "         [0.8950, 0.9022, 0.0172, 0.0176, 0.3202]],\n",
            "\n",
            "        [[0.4712, 0.3305, 0.4078, 0.9796, 0.1717],\n",
            "         [0.6894, 0.8854, 0.8833, 0.8838, 0.9970],\n",
            "         [0.3611, 0.9187, 0.0893, 0.2255, 0.6699],\n",
            "         [0.6828, 0.6481, 0.4441, 0.6411, 0.0795]],\n",
            "\n",
            "        [[0.1536, 0.5694, 0.4721, 0.0741, 0.1530],\n",
            "         [0.3897, 0.9793, 0.9707, 0.7052, 0.8337],\n",
            "         [0.0832, 0.5157, 0.0460, 0.3986, 0.3475],\n",
            "         [0.9157, 0.0498, 0.8912, 0.9541, 0.0368]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-dy0VY077gG"
      },
      "source": [
        "###Extending the dimension by unsqueeze operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt6GvYtJWtSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba7ecdfc-3939-4850-9c42-4478ef0d1d31"
      },
      "source": [
        "x = torch.rand(3,4,5,6)\n",
        "print(x.size())\n",
        "#print(x)\n",
        "print(x.unsqueeze(dim=2).size())\n",
        "#print(x.unsqueeze(dim=2))\n",
        "print(x.unsqueeze(dim=3).size())\n",
        "print(x.unsqueeze(dim=4).size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4, 5, 6])\n",
            "torch.Size([3, 4, 1, 5, 6])\n",
            "torch.Size([3, 4, 5, 1, 6])\n",
            "torch.Size([3, 4, 5, 6, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE2GJRkBasOw"
      },
      "source": [
        "###Numpy Bridge\n",
        "####Converting a numpy array to torch tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26-U02yFZGT0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "801ca7cd-c98c-4442-fd8f-906397265f14"
      },
      "source": [
        "x = np.array([[1.0,2],[3,4]])\n",
        "print(type(x))\n",
        "y = torch.from_numpy(x)\n",
        "print(y)\n",
        "y.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.DoubleTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsAxO1Sj_yL0"
      },
      "source": [
        "####Converting a torch tensor to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei-KpF1MZLm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8388a41d-5199-495f-8009-f056aa935b7a"
      },
      "source": [
        "z = y.numpy()\n",
        "z.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNJZQcnddMoC"
      },
      "source": [
        "**CUDA Tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7gXIIyjAXqO"
      },
      "source": [
        "####Checking the availability of CUDA/GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wqlDh-VbFWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd4cd9b-98a0-45a6-cd84-a73b98313b49"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkIDqwYPdZpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc5cb14-68af-4d0d-a049-6d2d9e1676e0"
      },
      "source": [
        "# Linux bash command to print the status of nvidia gpu (memory and processes)\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb  8 04:00:58 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8             11W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXpbPJ0dAnze"
      },
      "source": [
        "####Defining the device object (cpu/gpu)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0heiVkdBdiAe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ff93700a-965a-43ec-ca52-1054e9b6c5c7"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "x = torch.rand(3,3)\n",
        "print(x)\n",
        "x.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3964, 0.7500, 0.6854],\n",
            "        [0.8963, 0.5351, 0.6966],\n",
            "        [0.7430, 0.6964, 0.7516]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR2cjesYAsYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c957c7b6-ae15-4b46-b611-d2c39cc06748"
      },
      "source": [
        "x = x.to(device)\n",
        "x.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.cuda.FloatTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzgU1Lw2A2qc"
      },
      "source": [
        "\n",
        "###Transferring the tensor to the respective device (here cpu->gpu)\n",
        "####Transferring the tensor from gpu->cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9VMq1zJd-N9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20f59432-1b1e-4a76-9e31-deba2cb1a90e"
      },
      "source": [
        "# Transferring the tensor from gpu->cpu\n",
        "device_cpu = torch.device(\"cpu\")\n",
        "x = x.to(device_cpu)\n",
        "x.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-nqAVFQjjq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "000bf0a4-c0d6-4e9d-d920-2703535bf2a4"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "N=100\n",
        "D_in=10\n",
        "H=100\n",
        "D_out=1\n",
        "\n",
        "x = Variable(torch.randn(N, D_in), requires_grad=False)\n",
        "y = Variable(torch.randn(N, D_out), requires_grad=False)\n",
        "w1 = Variable(torch.randn(D_in,H), requires_grad=True)\n",
        "w2 = Variable(torch.randn(H, D_out), requires_grad=True)\n",
        "b1 = Variable(torch.randn(H), requires_grad=True)\n",
        "b2 = Variable(torch.randn(D_out), requires_grad=True)\n",
        "learning_rate = 1e-5\n",
        "\n",
        "for t in range(5000):\n",
        "    y_pred = ((x.mm(w1)+b1).clamp(min=0).mm(w2)+b2) #FP\n",
        "    loss = (y_pred-y).pow(2).sum() #Loss computation\n",
        "    loss.backward() #BP\n",
        "    w2.data -= learning_rate*w2.grad #WU\n",
        "    w1.data -= learning_rate*w1.grad #WU\n",
        "    b2.data -= learning_rate*b2.grad #WU\n",
        "    b1.data -= learning_rate*b1.grad #WU\n",
        "    w1.grad.data.zero_() #Reset gradients\n",
        "    w2.grad.data.zero_() #Reset gradients\n",
        "    b1.grad.data.zero_() #Reset gradients\n",
        "    b2.grad.data.zero_() #Reset gradients\n",
        "    if t%100==0:\n",
        "      print(loss)\n",
        "      print(loss.type())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(33387.5234, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(1262.6506, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(593.7207, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(368.3163, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(258.7665, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(192.3369, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(148.0052, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(117.0064, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(94.3429, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(77.3563, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(64.2621, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(53.8821, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(45.5069, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(38.7133, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(33.0925, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(28.4550, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(24.5454, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(21.1841, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(18.3205, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(15.8803, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(13.7962, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(12.0118, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(10.4876, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(9.1631, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(8.0057, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(7.0125, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(6.1608, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(5.4269, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(4.7908, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(4.2368, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(3.7595, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(3.3472, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(2.9887, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(2.6733, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(2.3942, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(2.1468, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(1.9271, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(1.7322, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(1.5596, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(1.4055, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(1.2676, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(1.1442, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(1.0335, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(0.9342, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(0.8452, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(0.7653, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(0.6932, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(0.6285, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(0.5698, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n",
            "tensor(0.5168, grad_fn=<SumBackward0>)\n",
            "torch.FloatTensor\n"
          ]
        }
      ]
    }
  ]
}