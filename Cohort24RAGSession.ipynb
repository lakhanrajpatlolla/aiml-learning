{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakhanrajpatlolla/aiml-learning/blob/master/Cohort24RAGSession.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jzxTJUa4YSGZ",
        "outputId": "4b8b7c34-84eb-4040-f9f1-dcf3aa2401db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.75.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.54)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai faiss-cpu tiktoken python-dotenv pypdf langchain-community langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4xrTl67ZKxG",
        "outputId": "fea24bc5-132d-4c43-8f5f-2c3e42704039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.3.23\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
            "Required-by: langchain-community\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "OPEN_AI_KEY = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "306Wu6A8ZVlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "8lP4b6_9Zj0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/doc202517482201.pdf\"\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "pages = loader.load()\n",
        "print(f\"🤷‍♂️loaded {len(pages)} Pages\")\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=100)\n",
        "chunks = splitter.split_documents(pages)\n",
        "print(f\"🤷‍♂️split into {len(chunks)} chunks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wrr6qgK0Z4gU",
        "outputId": "03f0a87a-cfd5-401f-efe0-e5035497981c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤷‍♂️loaded 10 Pages\n",
            "🤷‍♂️split into 47 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=OPEN_AI_KEY)\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "print(\"Vector store created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyn3d1ataoZe",
        "outputId": "f9725b52-28e5-44df-a90c-d2bed7b89b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector store created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKl8FKZFazir",
        "outputId": "e48aaab4-ae6a-49f7-b57c-306a03930e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.75.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "query = \"what is GDP growth rate of india for 2024-25 ?\"\n",
        "direct_response=client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": query}\n",
        "    ]\n",
        ")\n",
        "print(\"Gdp without RAG\")\n",
        "print(direct_response.choices[0].message.content.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoHHJ7H3aupl",
        "outputId": "d8e62f6e-81d4-4231-f2c1-e537f2acf6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gdp without RAG\n",
            "It is not possible to accurately predict the GDP growth rate for India in 2024-25 as it depends on various economic factors and events that may influence the economy in the future. Projections and estimates for future GDP growth rates are typically made closer to the actual time period based on current economic conditions and trends.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = vectorstore.similarity_search(query,k=3)\n",
        "context = \"\\n\\n\".join([doc.page_content for doc in results])"
      ],
      "metadata": {
        "id": "geJB6PzHbTD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Augmentation\n",
        "prompt = f\"\"\"\n",
        "use the following document context to answer the question.\n",
        "context:\n",
        "{context}\n",
        "Question:{query}\n",
        "Answer:\"\"\"\n",
        "rag_response = client.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo\",\n",
        "   messages=[\n",
        "       {\"role\": \"system\", \"content\": \"You answer based only on the given document context.\"},\n",
        "       {\"role\": \"user\", \"content\": prompt}\n",
        "   ]\n",
        "\n",
        ")\n",
        "print(\"GPT with RAG Answer\")\n",
        "print(rag_response.choices[0].message.content.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "impjVHzyb1RJ",
        "outputId": "4e2f2fbe-f350-4bdd-ca69-b639c2cc9279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT with RAG Answer\n",
            "The GDP growth rate of India for 2024-25 is estimated at 6.4%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings,ChatOpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n"
      ],
      "metadata": {
        "id": "GInI0K5Dc8E1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/ens_d2.pdf\"\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "pages = loader.load()\n",
        "print(f\"🤷‍♂️loaded {len(pages)} Pages\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ5-Iaa4tIoy",
        "outputId": "5f3d720e-c5a8-40c6-fa92-c6b8e6532057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤷‍♂️loaded 2 Pages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
        "chunks = splitter.split_documents(pages)\n",
        "print(f\"🤷‍♂️split into {len(chunks)} chunks\")\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhjG7m0BtXi0",
        "outputId": "9bd8c3f8-9d07-41ba-931c-a2e950ce4ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤷‍♂️split into 7 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "print(\"Vector store created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osapb2CDtdn-",
        "outputId": "59bbee8f-0894-494e-bd2a-908df3c40f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector store created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0)"
      ],
      "metadata": {
        "id": "W02dM6LRttQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_agent_retriever(keyword):\n",
        "  relevant_docs = [doc for doc in chunks if keyword.lower() in doc.page_content.lower()]\n",
        "  local_vectorstore = FAISS.from_documents(relevant_docs, embeddings)\n",
        "  return local_vectorstore.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":2})\n"
      ],
      "metadata": {
        "id": "szQEEdcAtuu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agentA = RetrievalQA.from_chain_type(llm=llm,retriever=get_agent_retriever(\"bagging\"))\n",
        "agentB = RetrievalQA.from_chain_type(llm=llm,retriever=get_agent_retriever(\"boosting\"))\n",
        "agentC = RetrievalQA.from_chain_type(llm=llm,retriever=get_agent_retriever(\"variance\"))"
      ],
      "metadata": {
        "id": "ln_ZLimBuegM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#co-ordinator\n",
        "def coordinator(query):\n",
        "  print('Query',query)\n",
        "  responseA = agentA.run(query)\n",
        "  responseB = agentB.run(query)\n",
        "  responseC = agentC.run(query)\n",
        "  final = llm.invoke([\n",
        "      {'role': 'system', 'content': 'You are a helpful coordinator combining answers from multiple expert agents.'},\n",
        "\n",
        "      {'role': 'user', 'content': f\"\"\"\n",
        "        Given the following agent reponses,merge them into a clear and unified answer to the question:\n",
        "        Bagging Expert:\\n{responseA}\\n # Changed from responseA['result'] to responseA\n",
        "        Boosting Expert:\\n{responseB}\\n # Changed from responseB['result'] to responseB\n",
        "        Concept Expert:\\n{responseC}\\n # Changed from responseC['result'] to responseC\n",
        "        Question: {query}\n",
        "        Answer:\n",
        "        \"\"\"}\n",
        "  ])\n",
        "  return final.content\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gbi2M4PKu0x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #test CO-RAG\n",
        "query=\"why do ensemble methods improve prediction accuracy?\"\n",
        "result = coordinator(query)\n",
        "print(\"Final Anser from all the three agents\",result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN1CuxrFwTNV",
        "outputId": "b93c9adf-cb58-4781-b9bb-f260c65ad53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query why do ensemble methods improve prediction accuracy?\n",
            "Final Anser from all the three agents Ensemble methods improve prediction accuracy by combining multiple models to reduce variance, decrease bias, and ultimately enhance predictions. Techniques like bagging, boosting, and stacking are utilized within ensemble methods to achieve these objectives. Bagging reduces variance by sampling and replacing data, boosting decreases bias by adjusting observation weights, and stacking combines multiple models to enhance overall prediction accuracy. By leveraging the strengths of different models and compensating for weaknesses, ensemble methods help reduce overfitting, increase generalization, and improve the overall accuracy of predictions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using Langgrpah Frame work for Agentic AI implimentation\n",
        "!pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nI1-LDTPwkND",
        "outputId": "08adbb06-40bc-40b6-a59d-beb4661a4831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.31-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.54)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.8 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.61-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (0.3.31)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (2.11.3)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.16)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.3.31-py3-none-any.whl (145 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.2/145.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.24-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.61-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.3.31 langgraph-checkpoint-2.0.24 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.61 ormsgpack-1.9.1 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings,ChatOpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langgraph.graph import END,StateGraph"
      ],
      "metadata": {
        "id": "gtVQNSPn0XLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/ens_d2.pdf\"\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "pages = loader.load()\n",
        "print(f\"🤷‍♂️loaded {len(pages)} Pages\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AM03ed21ChS",
        "outputId": "5aa3fd0b-4608-4172-a8fe-0e420e997852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤷‍♂️loaded 2 Pages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
        "docs = splitter.split_documents(pages)\n",
        "print(f\"🤷‍♂️split into {len(docs)} chunks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwJpTPRl1R2X",
        "outputId": "ec88c518-daa4-4d99-b498-f8bb3accdd13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤷‍♂️split into 7 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "print(\"Vector store created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qf4SKXj1boz",
        "outputId": "6a754355-bfd3-4695-ebb7-d190ef62eb94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector store created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0)"
      ],
      "metadata": {
        "id": "NhfuvIkW1hlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_retriever(ketword):\n",
        "  filtered = [doc for doc in docs if ketword.lower() in doc.page_content.lower()]\n",
        "  store = FAISS.from_documents(filtered, embeddings)\n",
        "  return store.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":2})"
      ],
      "metadata": {
        "id": "QUrF1w6G1nnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Agent chains\n",
        "BaggingQA = RetrievalQA.from_chain_type(llm=llm,retriever=create_retriever(\"bagging\"))\n",
        "BoostingQA = RetrievalQA.from_chain_type(llm=llm,retriever=create_retriever(\"boosting\"))\n",
        "ConceptQA = RetrievalQA.from_chain_type(llm=llm,retriever=create_retriever(\"variance\"))"
      ],
      "metadata": {
        "id": "XsKMBMhO136z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LanggraphNodes\n",
        "def bagging_node(state):\n",
        "  query = state[\"query\"]\n",
        "  return {\"bagging\": BaggingQA.invoke(query)[\"result\"],**state}\n",
        "def boosting_node(state):\n",
        "  query = state[\"query\"]\n",
        "  return {\"boosting\": BoostingQA.invoke(query)[\"result\"],**state}\n",
        "def concept_node(state):\n",
        "  query = state[\"query\"]\n",
        "  return {\"concept\": ConceptQA.invoke(query)[\"result\"],**state}\n",
        "\n",
        "def coordinator_node(state):\n",
        "  query = state[\"query\"]\n",
        "  bagging = state.get(\"bagging\",\"\")\n",
        "  boosting = state.get(\"boosting\",\"\")\n",
        "  concept = state.get(\"concept\",\"\")\n",
        "  prompt = f\"\"\"\n",
        "  you are a helpful coordinator AI.merge insights from experts into unified answer.\n",
        "  Bagging Expert :{bagging},\n",
        "  Boosting Expert :{boosting},\n",
        "  Concept Expert :{concept},\n",
        "  Question: {query}\n",
        "  \"\"\"\n",
        "  response = llm.invoke(prompt).content\n",
        "  return {\"final_answer\":response,**state}\n"
      ],
      "metadata": {
        "id": "1ssUbQNw2E_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Langraph\n",
        "from typing import TypedDict\n",
        "class CoRAGstate(TypedDict):\n",
        "  query : str\n",
        "  bagging:str\n",
        "  boosting:str\n",
        "  concept:str\n",
        "  final_answer:str\n",
        "\n",
        "graph = StateGraph(state_schema=CoRAGstate)\n",
        "graph.add_node(\"BaggingExpert\",bagging_node)\n",
        "graph.add_node(\"BoostingExpert\",boosting_node)\n",
        "graph.add_node(\"ConceptExpert\",concept_node)\n",
        "graph.add_node(\"Coordinator\",coordinator_node)\n",
        "\n",
        "graph.set_entry_point(\"BaggingExpert\")\n",
        "graph.add_edge(\"BaggingExpert\",\"BoostingExpert\")\n",
        "graph.add_edge(\"BoostingExpert\",\"ConceptExpert\")\n",
        "graph.add_edge(\"ConceptExpert\",\"Coordinator\")\n",
        "graph.add_edge(\"Coordinator\",END)\n",
        "\n",
        "coRAG_app = graph.compile()"
      ],
      "metadata": {
        "id": "jb7Roea_3ZbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"why do ensemble methods improve prediction accuracy?\"\n",
        "result = coRAG_app.invoke({'query':query})\n",
        "print(\"Final Answer\",result[\"final_answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE4LG3Wz4nyI",
        "outputId": "56718694-480f-4f63-ad2e-654440af62d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Answer Ensemble methods improve prediction accuracy by combining multiple models to reduce variance, decrease bias, and ultimately improve predictions. Bagging reduces variance by sampling and replacing data, boosting decreases bias by giving more weight to misclassified data points, and stacking combines multiple models to learn from their strengths and weaknesses. By leveraging the strengths of different models and reducing their weaknesses, ensemble methods can capture more complex patterns in the data and make more accurate predictions than any single model could achieve on its own.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(coRAG_app)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q1bHdTR49WW",
        "outputId": "9cb768f4-cd56-4951-cbeb-314756ac4b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<langgraph.graph.state.CompiledStateGraph object at 0x7e8c02d77850>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d7b_5QJ53dL",
        "outputId": "5df24423-c43e-43b8-f35e-29ad9dac8b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (0.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "graph.get_graph().draw(\"coRAG_graph.png\",format=\"png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "BG0Yotdp6Huk",
        "outputId": "621f2fa3-1bc5-4afd-c08c-a6a8de026986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'StateGraph' object has no attribute 'get_graph'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-99ac186b4306>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"coRAG_graph.png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'StateGraph' object has no attribute 'get_graph'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lh8tJBSV8GFL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}