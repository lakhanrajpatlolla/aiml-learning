{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakhanrajpatlolla/aiml-learning/blob/master/U4W18_64_Student_Teacher_Network_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKdGI6KEpPsC"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK_cVGGx4JoO"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6s6kEQH4Lye"
      },
      "source": [
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "\n",
        "*  Classify the Fashion MNIST dataset using a teacher network  \n",
        "*  Understand how the student network uses the outputs of the teacher network\n",
        "*  Establish that student - teacher network improves classification accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG5djFYcn8VQ",
        "cellView": "form"
      },
      "source": [
        "#@title Experiment Explanation Video\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<video width=\"800\" height=\"300\" controls>\n",
        "  <source src=\"https://cdn.talentsprint.com/aiml/AIML_BATCH_HYD_7/March31/student_teacher_network.mp4\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dZTBVmq4d0u"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s7GpYrkCaSB"
      },
      "source": [
        "### History"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-sRjaldCcCI"
      },
      "source": [
        "The original MNIST dataset contains handwritten digits. People from AI/ML or Data Science community love this dataset. They use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset they would try on. As per popular belief, If the algorithm doesn’t work on MNIST, it won’t work at all. Well, if algorithm works on MNIST, it may still fail on other datasets.\n",
        "\n",
        "\n",
        "As per the original [paper](https://arxiv.org/abs/1708.07747) describing about Fashion-MNIST, It is a dataset recomposed from the product pictures of Zalando’s websites. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits.\n",
        "\n",
        "There are some good reasons for the challenges faced by MNIST dataset:\n",
        "\n",
        "* MNIST is too easy - Neural networks can achieve 99.7% on MNIST easily, and similarly, even classic ML algorithms can achieve 97%.\n",
        "\n",
        "* MNIST is overused - Almost everyone who has experience with deep learning has come across MNIST at least once.\n",
        "\n",
        "* MNIST cannot represent modern CV task\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijqHaydutZ5K"
      },
      "source": [
        "### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ANHcoEyg_gp"
      },
      "source": [
        "The dataset choosen for this experiment is Fashion-MNIST. The dataset is made up of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images.\n",
        "\n",
        "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255.\n",
        "\n",
        "**Labels / Classes**\n",
        "\n",
        "0 - T-shirt/top\n",
        "\n",
        "1 - Trouser\n",
        "\n",
        "2 - Pullover\n",
        "\n",
        "3 - Dress\n",
        "\n",
        "4 - Coat\n",
        "\n",
        "5 - Sandal\n",
        "\n",
        "6 - Shirt\n",
        "\n",
        "7 - Sneaker\n",
        "\n",
        "8 - Bag\n",
        "\n",
        "9 - Ankle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqcsYSOi4rIF"
      },
      "source": [
        "## AI / ML Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jNGJ8YH4tJP"
      },
      "source": [
        "### Student - Teacher Network\n",
        "\n",
        "In this experiment, we train our Student - Teacher Network to classify images in the dataset. There are several ways to perform image classification. However, the performance of image classification can often be significantly improved by combining multiple models together which are called ensemble methods. Though beneficial, ensemble methods can be computationally expensive.\n",
        "\n",
        "Therefore, an alternative approach, appropriate for deep learning schemes, is to adopt student-teacher training.\n",
        "\n",
        "In this training approach, there is a huge neural network known as the teacher network which performs classification tasks. The standard approach is to train the student model (this model/network is desirably smaller) on the posterior outputs of the teacher network.\n",
        "\n",
        "You can look at the student - teacher network sample below:\n",
        "\n",
        "<img src = \"https://3.bp.blogspot.com/-eD3Mc4FLsvA/WvN6BweGY_I/AAAAAAAACuU/OZqGR1UUvL05Ctr1b8JD3SaKlCNCZVMdACLcBGAs/s1600/f2.png\" width=\"600\" height=\"500\">\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2418775\" #@param {type:\"string\"}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEzlYL4CDrmE"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"9959000490\" #@param {type:\"string\"}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9bda632-2afd-490e-a51f-3ed227ccac52"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import re\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"U4W18_64_Student_Teacher_Network_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    from IPython.display import HTML, display\n",
        "    ipython.magic(\"sx pip3 install torch\")\n",
        "    ipython.magic(\"sx pip3 install torchvision\")\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_inclass_mentor\": Mentor_support}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://learn-iiith.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getWalkthrough():\n",
        "  try:\n",
        "    if not Walkthrough:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Walkthrough\n",
        "  except NameError:\n",
        "    print (\"Please answer Walkthrough Question\")\n",
        "    return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2418775&recordId=2433\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlMC9Lm8pPsJ"
      },
      "source": [
        "### Importing required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uAKIkAUeH2c"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boiDSlFEeH2f"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Oi1SoaaeH2g"
      },
      "source": [
        "num_epochs = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbm-8HxIqvxR"
      },
      "source": [
        "### Initializing CUDA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoCx_gzBpPsT"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHRJBZlreH2i"
      },
      "source": [
        "### Downloading Fashion MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-iRe1wveH2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b457e0-433f-48ce-8716-ed402c93fd69"
      },
      "source": [
        "train_dataset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 13.1MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 209kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.88MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 22.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExlB1XSJeH2m"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DojbnZEEeH2n"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuUceYM_eH2p"
      },
      "source": [
        "### Defining the Teacher Network\n",
        "\n",
        "A comparatively bigger and deeper network as compared to the student network defined later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PsNscxEeH2p"
      },
      "source": [
        "class Teacher(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Teacher, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.fc1 = nn.Linear(7*7*32, 300)\n",
        "        self.fc2 = nn.Linear(300, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        out = F.log_softmax(out, dim=1)\n",
        "        return out\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSkstHt2eH2r"
      },
      "source": [
        "### Defining the student network\n",
        "\n",
        "A comparatively smaller and shallower network than the teacher."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12YRY5ereH2s"
      },
      "source": [
        "class Student(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Student, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.fc1 = nn.Linear(14*14*16, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        return F.log_softmax(out, dim=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qOZrRjleH2u"
      },
      "source": [
        "<b>The below function is called to reinitialize the weights of the network and define the required loss criterion and the optimizer.</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h49LnI0_eH2v"
      },
      "source": [
        "def reset_model(is_teacher = True):\n",
        "    if is_teacher == True:\n",
        "        net = Teacher()\n",
        "    else:\n",
        "        net = Student()\n",
        "\n",
        "    net = net.to(device)\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "    return net, criterion, optimizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L_df1wTeH2x"
      },
      "source": [
        "### Training the teacher network\n",
        "\n",
        "The first step is to train the teacher network to become an expert. We move ahead with regular training procedure using the cross entropy loss and the Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRX65jtFeH2y"
      },
      "source": [
        "teacher, criterion, optimizer = reset_model()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbConbCBeH20"
      },
      "source": [
        "# Train the Model\n",
        "\n",
        "def training(net, reset = True):\n",
        "    if reset == True:\n",
        "        net, criterion, optimizer = reset_model()\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "    net.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        accuracy = []\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            temp_labels = labels\n",
        "\n",
        "\n",
        "            # Forward + Backward + Optimize\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct = (predicted == temp_labels).sum().item()\n",
        "            accuracy.append(correct/float(batch_size))\n",
        "\n",
        "        print('Epoch: %d, Loss: %.4f, Accuracy: %.4f' %(epoch+1,total_loss, (sum(accuracy)/float(len(accuracy)))))\n",
        "\n",
        "    return net"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSWR0Yv6eH22"
      },
      "source": [
        "### Testing the teacher network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltz0Dqt2eH23"
      },
      "source": [
        "# Test the Model\n",
        "def testing(net):\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the network on the 10000 test images: %.2f %%' % (100.0 * correct / total))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os1GlnImeH26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58a23593-0d32-42da-a787-d04314f2e5ca"
      },
      "source": [
        "reset = True\n",
        "teacher = training(teacher, reset)\n",
        "testing(teacher)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 229.4376, Accuracy: 0.8623\n",
            "Epoch: 2, Loss: 152.3746, Accuracy: 0.9063\n",
            "Epoch: 3, Loss: 129.8426, Accuracy: 0.9198\n",
            "Epoch: 4, Loss: 114.0117, Accuracy: 0.9293\n",
            "Epoch: 5, Loss: 102.0829, Accuracy: 0.9362\n",
            "Epoch: 6, Loss: 89.5617, Accuracy: 0.9444\n",
            "Epoch: 7, Loss: 80.4057, Accuracy: 0.9495\n",
            "Epoch: 8, Loss: 69.4561, Accuracy: 0.9573\n",
            "Epoch: 9, Loss: 61.2803, Accuracy: 0.9610\n",
            "Epoch: 10, Loss: 52.8880, Accuracy: 0.9672\n",
            "Test Accuracy of the network on the 10000 test images: 92.22 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "013uWGu6eH2-"
      },
      "source": [
        "### Parameters for Student Network\n",
        "\n",
        "Here, we define a few more parameters of the student network. In the student network, we will train with the soft targets as well the hard targets. The soft targets will be calculated by the following equation:\n",
        "\n",
        "$$\n",
        "f(z_{i}) = \\frac{\\exp(z_{i})}{\\sum_{j}\\exp(z_{j})}\n",
        "$$\n",
        "\n",
        "This results in softening out the outputs of the teacher and this can be used as hints for the student network.\n",
        "\n",
        "The loss doesn't need to get backpropagated across the teacher network and therefore we make the corresponding modification.\n",
        "\n",
        "Also, for training with the soft labels, we use mean square error loss since using a Cross Entropy loss for soft labels makes no sense."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "priVPxWieH2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6399f4e-e0e3-4f95-e4f1-4a5690ee3768"
      },
      "source": [
        "temperature = 1.5\n",
        "for p in teacher.parameters():\n",
        "    p.requires_grad= False\n",
        "\n",
        "student, criterion, optimizer = reset_model(is_teacher = False)\n",
        "alpha = 0.6\n",
        "\n",
        "mse_criterion = nn.MSELoss()\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "print(student)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc1): Linear(in_features=3136, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXhJ0v3veH3B"
      },
      "source": [
        "### Training and testing the student network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5sNoyAXeH3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d5ea63-57c2-4351-e3f0-307c07cf5de3"
      },
      "source": [
        "# Train the Model\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    accuracy = []\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        temp_labels = labels\n",
        "\n",
        "        # Forward + Backward + Optimize\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        student_outputs = student(images)\n",
        "\n",
        "        hard_outputs = teacher(images)\n",
        "        soft_outputs = hard_outputs/ temperature\n",
        "        soft_outputs = softmax(soft_outputs)\n",
        "\n",
        "        hard_loss = criterion(student_outputs, labels)\n",
        "        soft_loss = mse_criterion(student_outputs, soft_outputs)\n",
        "        loss = alpha*hard_loss + (1-alpha)*soft_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(student_outputs.data, 1)\n",
        "        correct = (predicted == temp_labels).sum().item()\n",
        "        accuracy.append(correct/float(batch_size))\n",
        "\n",
        "    print('Epoch: %d, Loss: %.4f, Accuracy: %.4f' %(epoch+1,total_loss, (sum(accuracy)/float(len(accuracy)))))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 2067.0100, Accuracy: 0.8277\n",
            "Epoch: 2, Loss: 2033.3517, Accuracy: 0.8738\n",
            "Epoch: 3, Loss: 2027.7542, Accuracy: 0.8833\n",
            "Epoch: 4, Loss: 2024.2340, Accuracy: 0.8890\n",
            "Epoch: 5, Loss: 2021.2873, Accuracy: 0.8942\n",
            "Epoch: 6, Loss: 2019.7211, Accuracy: 0.8964\n",
            "Epoch: 7, Loss: 2018.5363, Accuracy: 0.8985\n",
            "Epoch: 8, Loss: 2017.5701, Accuracy: 0.9018\n",
            "Epoch: 9, Loss: 2016.9660, Accuracy: 0.9038\n",
            "Epoch: 10, Loss: 2016.3975, Accuracy: 0.9038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qUZyRuueH3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f07872-27fd-4247-ff3a-1d50ded6359a"
      },
      "source": [
        "testing(student)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the network on the 10000 test images: 89.23 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHgEKnpYeH3M"
      },
      "source": [
        "### References\n",
        "\n",
        "1. https://arxiv.org/abs/1412.6550\n",
        "2. https://www.cs.toronto.edu/~hinton/absps/distillation.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-b-CEcpkOCi"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12SwfIaukOCj"
      },
      "source": [
        "#@title State True or False: Increasing temperature term makes the distribution of output probabilities flatter? Refer <a href=\"https://www.quora.com/What-is-the-temperature-parameter-in-deep-learning\">Link</a> { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"TRUE\" #@param [\"\",\"TRUE\", \"FALSE\"]\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0DzTLAMkOCj"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good, But Not Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlMms_IykOCj"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"good\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHnMPzf_kOCk"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRKla4emkOCk"
      },
      "source": [
        "#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Walkthrough = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtkER1AwkOCk"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-UhjrabkOCk"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "MUHD7LC0kOCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5cbf4c8-313f-44a9-f097-a9f861fe63b4"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 2433\n",
            "Date of submission:  05 Apr 2025\n",
            "Time of submission:  13:15:31\n",
            "View your submissions: https://learn-iiith.talentsprint.com/notebook_submissions\n"
          ]
        }
      ]
    }
  ]
}