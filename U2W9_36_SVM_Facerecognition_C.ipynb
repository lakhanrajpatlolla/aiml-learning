{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakhanrajpatlolla/aiml-learning/blob/master/U2W9_36_SVM_Facerecognition_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fpVc1Qdu-Uq"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWrO0ier8ygw"
      },
      "source": [
        "##Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2XhNmWh4teT"
      },
      "source": [
        "\n",
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* extract meaningful features from the images using PCA\n",
        "\n",
        "* apply SVM on the extracted data and recognize the face\n",
        "\n",
        "**NOTE:**  The intent of this experiment is to understand the SVM parameters and tune your classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj2Y2HwZ9fzW",
        "cellView": "form"
      },
      "source": [
        "#@title Experiment Walthrough Video\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<video width=\"854\" height=\"480\" controls>\n",
        "  <source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/misc/svm_facerecognition.mp4\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2INZXkO87ld"
      },
      "source": [
        "##Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_reikMZBdZ0o"
      },
      "source": [
        "### Description\n",
        "\n",
        "The dataset chosen for this experiment is a preprocessed excerpt of the “Labeled Faces in the Wild”, aka LFW.\n",
        "\n",
        "Labeled Faces in the Wild, a database of face photographs designed for studying the problem of unconstrained face recognition. The data set contains more than 13,000 images of faces collected from the web. Each face has been labeled with the name of the person pictured. 1680 of the people pictured have two or more distinct photos in the data set. The only constraint on these faces is that they were detected by the Viola-Jones face detector.\n",
        "\n",
        "\n",
        "To know more about the dataset you can refer below link :\n",
        "\n",
        "\n",
        "http://vis-www.cs.umass.edu/lfw/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxwqZ2bz9DKq"
      },
      "source": [
        "##Domain Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogwMiFMv5Ehn"
      },
      "source": [
        "\n",
        "As it is known by you that every face is different and a face has various features. Some of us have a broad forehead, some have narrow, some have fuller lips whereas some have thinner lips, etc. Additionally, every feature of the face has different variations. An ideal face recognition system should be able to consider all the variations and the challenges faced to recognize a face accurately.\n",
        "\n",
        "\n",
        "###Below we have listed a few challenges\n",
        "\n",
        "\n",
        "**Illumination:** Lighting aspect\n",
        "\n",
        "**Background:** The placement of the subject also serves as a significant contributor to the limitations.\n",
        "\n",
        "**Pose:** The movements of the head\n",
        "\n",
        "**Occlusion:**  beard, mustache, accessories (goggles, caps, mask, etc.) also meddle with the evaluation of a face recognition system. The Presence of such components makes the subject diverse and hence it becomes difficult for the system to operate in a non-simulated environment.\n",
        "\n",
        "**Expressions:** A change is an expression brings a change into all the aspects of the face.\n",
        "\n",
        "All these make the problem very complex."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m46mVe379I4w"
      },
      "source": [
        "##AI/ML Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCP6ASsNSHZn"
      },
      "source": [
        "### SVM\n",
        "\n",
        "SVM stands for Support vector machines. It used for both classification and regression tasks. SVM works by searching the linear optimal separating hyperplane (decision boundary). The logic is that decision boundary with large margin is better when handling unseen data compared to decision boundary with a small margin. When the data is not\n",
        "linearly separable, SVM transforms original data into a higher dimension using a nonlinear mapping to obtain the separating hyperplane.\n",
        "\n",
        "\n",
        "To know more about SVM you can refer the below link :\n",
        "\n",
        "https://www.quantstart.com/articles/Support-Vector-Machines-A-Guide-for-Beginners\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2418775\" #@param {type:\"string\"}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEzlYL4CDrmE"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"9959000490\" #@param {type:\"string\"}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form",
        "outputId": "d5dd19d5-c715-421e-9995-39406a1288e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import re\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"U2W9_36_SVM_Facerecognition_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    from IPython.display import HTML, display\n",
        "    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/social_advertising.csv\")\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_inclass_mentor\": Mentor_support}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://learn-iiith.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getWalkthrough():\n",
        "  try:\n",
        "    if not Walkthrough:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Walkthrough\n",
        "  except NameError:\n",
        "    print (\"Please answer Walkthrough Question\")\n",
        "    return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2418775&recordId=1670\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcuHkugaj3m3"
      },
      "source": [
        "As an example of support vector machines in action, let's take a look at the facial recognition problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbslM_liu-Uw"
      },
      "source": [
        "## Importing the required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LELdxmTXu-Ux"
      },
      "source": [
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQVakGy5u-U6"
      },
      "source": [
        "## Loading the dataset from sklearn datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I54otvVpu-U8"
      },
      "source": [
        "faces = fetch_lfw_people(min_faces_per_person = 60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXgdNxglu-VB"
      },
      "source": [
        "# Checking for the target names (Label names)\n",
        "print(faces.target_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mGgg2NIu-VH"
      },
      "source": [
        "# Checking for the shape of images\n",
        "print(faces.images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJme-tkHu-VM"
      },
      "source": [
        "To get a sense of the data, let us visualize the faces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBjw0WRI44Vx"
      },
      "source": [
        "# Plotting the images in subplots\n",
        "n_row, n_col = 3, 3\n",
        "plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
        "\n",
        "for i in range(n_row * n_col):\n",
        "    plt.subplot(n_row, n_col, i + 1)\n",
        "    plt.imshow(faces.images[i], cmap='gray')\n",
        "    plt.title(faces.target_names[faces.target[i]], size=12)\n",
        "    plt.xticks(())\n",
        "    plt.yticks(())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtV2dvi5u-VT"
      },
      "source": [
        "Each image contains [62×47] or nearly 3,000 pixels. We could proceed by simply using each pixel value as a feature, but often it is more effective to use some sort of preprocessor to extract more meaningful features; here we will use a principal component analysis to extract 150 fundamental components to feed into our support vector machine classifier. We can do this most straightforwardly by packaging the preprocessor and the classifier into a single pipeline:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTj1BLlm2c8J"
      },
      "source": [
        "In PCA, the parameter `Whiten = True`, will remove some information from the transformed signal (the relative variance scales of the components) but can sometime improve the predictive accuracy of the downstream estimators by making their data respect some hard-wired assumptions. Whitening just makes our resulting data have a unit variance, which has been shown to produce better results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lgafnt5KkjS"
      },
      "source": [
        "In support vector machines, 'C' is a hyperparameter determining the penalty for misclassifying an sample. One method for handling imbalanced classes in support vector machines is to weight 'C' by classes, so that\n",
        "\n",
        "$C_k = C∗w_j$\n",
        "\n",
        "where $C$ is the penalty for misclassification, $w_j$ is a weight inversely proportional to class $j$’s frequency and\n",
        "$C_j$ is the $C$ value for class $j$. The general idea is to increase the penalty for misclassifying minority classes to prevent them from being “overwhelmed” by the majority class.\n",
        "\n",
        "In scikit-learn, for SVC we can set the values for $C_j$\n",
        " automatically by setting **class_weight='balanced'**.  The balanced argument automatically weighs classes such that:\n",
        "\n",
        "  $w_j = \\frac{n}{kn_j}$\n",
        "\n",
        "where $w_j$ is the weight to class $j$,  n is the number of samples, $n_j$ is the number of samples in class $j$\n",
        ", and k is the total number of classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QQCSwG03EYV"
      },
      "source": [
        "Note: Refer [make_pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html) from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7eea2_hu-VU"
      },
      "source": [
        "pca = PCA(n_components=150, whiten=True, random_state=42)\n",
        "svc = SVC(kernel='rbf', class_weight='balanced')\n",
        "model = make_pipeline(pca, svc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiE2ZI-8u-VY"
      },
      "source": [
        "For testing our classifier output, we will split the data into a training and testing set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUBB11zDu-VZ"
      },
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1vBhuOUtezl"
      },
      "source": [
        "# Checking for the shape of Xtest\n",
        "Xtest.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyTANFGBbzxy"
      },
      "source": [
        "# Checking for the shape of Xtrain\n",
        "Xtrain.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH1nwRcfu-Ve"
      },
      "source": [
        "Finally, we can use a grid search to explore combinations of parameters. Here we will adjust C (which controls the margin hardness) and gamma (which controls the size of the radial basis function kernel), and determine the best model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICQ49mEXu-Vf"
      },
      "source": [
        "param_grid = {'svc__C': [1, 5, 10, 50],      # It takes some time to run this cell\n",
        "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
        "grid = GridSearchCV(model, param_grid)\n",
        "\n",
        "# Starting the timer\n",
        "t0 = time()\n",
        "\n",
        "grid.fit(Xtrain, ytrain)\n",
        "\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print(grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d53OmgcMu-Vl"
      },
      "source": [
        "The optimal values fall toward the middle of our grid; if they fell at the edges, we would want to expand the grid to make sure we have found the true optimum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxMKr5QLu-Vm"
      },
      "source": [
        "Now with this model, we can predict the labels for the test data, which the model has not yet seen:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ4XreUeu-Vo"
      },
      "source": [
        "model = grid.best_estimator_\n",
        "y_pred = model.predict(Xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ0WkHsmu-Vs"
      },
      "source": [
        "Let's take a look at a few of the test images along with their predicted values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBskyaEQu-Vt"
      },
      "source": [
        "# Plotting the images in subplots\n",
        "n_rows, n_cols = 4, 6\n",
        "plt.figure(figsize=( 8, 6))\n",
        "\n",
        "for i in range(n_rows * n_cols):\n",
        "    plt.subplot(n_rows, n_cols, i + 1)\n",
        "    plt.imshow(Xtest[i].reshape(62, 47), cmap='gray')\n",
        "    plt.xticks(())\n",
        "    plt.yticks(())\n",
        "    plt.ylabel(faces.target_names[y_pred[i]].split()[-1],\n",
        "                   color='black' if y_pred[i] == ytest[i] else 'red')\n",
        "plt.suptitle('Predicted Names; Incorrect Labels in Red', size = 15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMz7csuUu-Vz"
      },
      "source": [
        "Out of this small sample, our optimal estimator mislabeled only a single face (Bush’s face in the bottom row was mislabeled as Blair). We can get a better sense of our estimator's performance using the classification report, which lists recovery statistics label by label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV9rW5o4u-V0"
      },
      "source": [
        "print(classification_report(ytest, y_pred,\n",
        "                            target_names=faces.target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYBEB5PCu-V8"
      },
      "source": [
        "Display the confusion matrix between these classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDpXQf_Yu-V-"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(ytest, y_pred)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=faces.target_names,\n",
        "            yticklabels=faces.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1Akml4Tu-WF"
      },
      "source": [
        "For a real-world facial recognition task, in which the photos do not come pre-cropped into nice grids, the only difference in the facial classification scheme is the feature selection: you would need to use a more sophisticated algorithm to find the faces, and extract features that are independent of the pixelation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noKU-O22u-WG"
      },
      "source": [
        "### Acknowledgment:  Python Data Science Handbook by Jake VanderPlas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4-oWiOAI7kZ"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvm-8H2RI7kd"
      },
      "source": [
        "#@title State True or False: The 'C' parameter controls the size of the radial basis function kernel. { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"FALSE\" #@param [\"\",\"TRUE\", \"FALSE\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good, But Not Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"Good\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94dIhQKDI7kf"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKzGvfdyI7kg"
      },
      "source": [
        "#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Walkthrough = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OjkIq7II7kh"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwLT_C0vI7ki"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "gPMKJg_eI7kj",
        "outputId": "2f4f876d-fd2f-44e8-be89-3f169d8b57ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 1670\n",
            "Date of submission:  09 Feb 2025\n",
            "Time of submission:  13:35:59\n",
            "View your submissions: https://learn-iiith.talentsprint.com/notebook_submissions\n"
          ]
        }
      ]
    }
  ]
}